<!-- LEGACY FILE NOTICE -->
> âš ï¸ æ­¤æª”æ¡ˆç‚ºèˆŠç‰ˆå‚™ä»½ï¼Œå·²è¢«æ–°æª”å–ä»£ï¼š [ch8-4-æ ¸å¿ƒç»„ä»¶è¯¦ç»†å®ç°.md](ch8-4-æ ¸å¿ƒç»„ä»¶è¯¦ç»†å®ç°.md)\n> å‚™ä»½æ™‚é–“ï¼š2025-10-31 12:28:26\n
---

**[â† è¿”å›ç¬¬8ç« é¦–é ](ch8-index.md)**

---

### 8.4 æ ¸å¿ƒç»„ä»¶è¯¦ç»†å®ç°

#### 8.4.1 çˆ¬è™«èŠ‚ç‚¹ç®¡ç†æœåŠ¡

**æŠ€æœ¯å®ç°ï¼š**
```python
import uuid
import time
import logging
from typing import Dict, List, Optional, Set
from concurrent.futures import ThreadPoolExecutor
import threading

class CrawlerNodeManager:
    """çˆ¬è™«èŠ‚ç‚¹ç®¡ç†æœåŠ¡ï¼Œè´Ÿè´£èŠ‚ç‚¹æ³¨å†Œã€çŠ¶æ€ç›‘æ§å’Œå¥åº·æ£€æŸ¥"""
    
    def __init__(
        self,
        config: Config,
        node_registry: NodeRegistry,
        health_checker: NodeHealthChecker,
        event_bus: EventBus
    ):
        self.config = config
        self.node_registry = node_registry
        self.health_checker = health_checker
        self.event_bus = event_bus
        self.logger = logging.getLogger(__name__)
        self.running = False
        self.heartbeat_thread = None
        self.health_check_thread = None
        self.lock = threading.Lock()
    
    def start(self):
        """å¯åŠ¨èŠ‚ç‚¹ç®¡ç†æœåŠ¡"""
        if self.running:
            return
        
        self.running = True
        self.logger.info("Starting crawler node manager")
        
        # å¯åŠ¨å¿ƒè·³å¤„ç†çº¿ç¨‹
        self.heartbeat_thread = threading.Thread(
            target=self._process_heartbeats,
            daemon=True
        )
        self.heartbeat_thread.start()
        
        # å¯åŠ¨å¥åº·æ£€æŸ¥çº¿ç¨‹
        self.health_check_thread = threading.Thread(
            target=self._perform_health_checks,
            daemon=True
        )
        self.health_check_thread.start()
        
        self.logger.info("Crawler node manager started")
    
    def stop(self):
        """åœæ­¢èŠ‚ç‚¹ç®¡ç†æœåŠ¡"""
        if not self.running:
            return
        
        self.running = False
        self.logger.info("Stopping crawler node manager")
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.heartbeat_thread:
            self.heartbeat_thread.join(timeout=5.0)
        if self.health_check_thread:
            self.health_check_thread.join(timeout=5.0)
        
        self.logger.info("Crawler node manager stopped")
    
    def register_node(
        self,
        node_info: NodeInfo
    ) -> NodeRegistrationResult:
        """
        æ³¨å†Œçˆ¬è™«èŠ‚ç‚¹
        
        :param node_info: èŠ‚ç‚¹ä¿¡æ¯
        :return: æ³¨å†Œç»“æœ
        """
        with self.lock:
            # ç”ŸæˆèŠ‚ç‚¹ID
            node_id = f"node-{uuid.uuid4().hex[:8]}"
            node_info.id = node_id
            
            # è®¾ç½®é»˜è®¤çŠ¶æ€
            node_info.status = "online"
            node_info.last_heartbeat = time.time()
            
            # ä¿å­˜èŠ‚ç‚¹ä¿¡æ¯
            self.node_registry.register_node(node_info)
            
            # å‘å¸ƒäº‹ä»¶
            self.event_bus.publish("node.registered", {
                "node_id": node_id,
                "node_info": node_info.to_dict()
            })
            
            self.logger.info("Node registered: %s", node_id)
            
            return NodeRegistrationResult(
                node_id=node_id,
                registration_time=time.time(),
                initial_status="online"
            )
    
    def unregister_node(self, node_id: str):
        """
        æ³¨é”€çˆ¬è™«èŠ‚ç‚¹
        
        :param node_id: èŠ‚ç‚¹ID
        """
        with self.lock:
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_info = self.node_registry.get_node(node_id)
            if not node_info:
                self.logger.warning("Node %s not found for unregistration", node_id)
                return
            
            # æ›´æ–°çŠ¶æ€
            node_info.status = "offline"
            node_info.last_heartbeat = 0
            self.node_registry.update_node(node_info)
            
            # å‘å¸ƒäº‹ä»¶
            self.event_bus.publish("node.unregistered", {
                "node_id": node_id
            })
            
            self.logger.info("Node unregistered: %s", node_id)
    
    def handle_heartbeat(self, node_id: str, heartbeat: NodeHeartbeat):
        """
        å¤„ç†èŠ‚ç‚¹å¿ƒè·³
        
        :param node_id: èŠ‚ç‚¹ID
        :param heartbeat: å¿ƒè·³æ•°æ®
        """
        with self.lock:
            # è·å–èŠ‚ç‚¹ä¿¡æ¯
            node_info = self.node_registry.get_node(node_id)
            if not node_info:
                self.logger.warning("Received heartbeat from unknown node: %s", node_id)
                return
            
            # æ›´æ–°èŠ‚ç‚¹ä¿¡æ¯
            node_info.last_heartbeat = time.time()
            node_info.status = "online"
            node_info.resources = heartbeat.resources
            node_info.load = heartbeat.load
            node_info.task_count = len(heartbeat.active_tasks)
            
            # ä¿å­˜æ›´æ–°
            self.node_registry.update_node(node_info)
            
            # å‘å¸ƒäº‹ä»¶
            self.event_bus.publish("node.heartbeat", {
                "node_id": node_id,
                "heartbeat": heartbeat.to_dict()
            })
    
    def _process_heartbeats(self):
        """å¤„ç†å¿ƒè·³è¶…æ—¶"""
        while self.running:
            try:
                current_time = time.time()
                timeout_threshold = current_time - self.config.heartbeat_timeout
                
                # æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹
                nodes = self.node_registry.get_all_nodes()
                for node in nodes:
                    if node.last_heartbeat < timeout_threshold:
                        self._handle_heartbeat_timeout(node.id)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                time.sleep(self.config.heartbeat_check_interval)
                
            except Exception as e:
                self.logger.error("Error in heartbeat processing: %s", str(e))
                time.sleep(1)
    
    def _handle_heartbeat_timeout(self, node_id: str):
        """å¤„ç†å¿ƒè·³è¶…æ—¶"""
        with self.lock:
            node_info = self.node_registry.get_node(node_id)
            if not node_info or node_info.status == "offline":
                return
            
            # æ›´æ–°çŠ¶æ€
            node_info.status = "unresponsive"
            self.node_registry.update_node(node_info)
            
            # å‘å¸ƒäº‹ä»¶
            self.event_bus.publish("node.timeout", {
                "node_id": node_id,
                "last_heartbeat": node_info.last_heartbeat
            })
            
            self.logger.warning("Node heartbeat timeout: %s", node_id)
    
    def _perform_health_checks(self):
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        while self.running:
            try:
                # è·å–éœ€è¦æ£€æŸ¥çš„èŠ‚ç‚¹
                nodes = self.node_registry.get_nodes_by_status("online")
                
                # å¹¶è¡Œæ‰§è¡Œå¥åº·æ£€æŸ¥
                with ThreadPoolExecutor(max_workers=self.config.health_check_workers) as executor:
                    futures = {
                        executor.submit(self._check_node_health, node.id): node.id
                        for node in nodes
                    }
                    
                    for future in futures:
                        node_id = futures[future]
                        try:
                            future.result()
                        except Exception as e:
                            self.logger.error("Health check failed for node %s: %s", node_id, str(e))
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                time.sleep(self.config.health_check_interval)
                
            except Exception as e:
                self.logger.error("Error in health check processing: %s", str(e))
                time.sleep(1)
    
    def _check_node_health(self, node_id: str):
        """æ£€æŸ¥èŠ‚ç‚¹å¥åº·çŠ¶æ€"""
        # 1. æ‰§è¡Œå¥åº·æ£€æŸ¥
        health_status = self.health_checker.check(node_id)
        
        # 2. æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
        with self.lock:
            node_info = self.node_registry.get_node(node_id)
            if not node_info:
                return
            
            # æ›´æ–°å¥åº·çŠ¶æ€
            node_info.health = health_status
            self.node_registry.update_node(node_info)
            
            # å¤„ç†å¥åº·çŠ¶æ€å˜åŒ–
            self._handle_health_status_change(node_id, node_info, health_status)
    
    def _handle_health_status_change(
        self,
        node_id: str,
        node_info: NodeInfo,
        new_health: NodeHealthStatus
    ):
        """å¤„ç†å¥åº·çŠ¶æ€å˜åŒ–"""
        # æª¢æŸ¥çŠ¶æ€æ˜¯å¦å‘ç”Ÿå˜åŒ–
        if node_info.health.status == new_health.status:
            return
        
        # æ›´æ–°çŠ¶æ€
        node_info.health = new_health
        self.node_registry.update_node(node_info)
        
        # å‘å¸ƒäº‹ä»¶
        self.event_bus.publish("node.health_changed", {
            "node_id": node_id,
            "old_status": node_info.health.status,
            "new_status": new_health.status,
            "details": new_health.details
        })
        
        # æ ¹æ®å¥åº·çŠ¶æ€é‡‡å–è¡ŒåŠ¨
        if new_health.status == "unhealthy":
            self._handle_unhealthy_node(node_id)
    
    def _handle_unhealthy_node(self, node_id: str):
        """å¤„ç†ä¸å¥åº·èŠ‚ç‚¹"""
        # 1. ä»è°ƒåº¦ä¸­ç§»é™¤èŠ‚ç‚¹
        self.event_bus.publish("scheduler.node_unavailable", {
            "node_id": node_id
        })
        
        # 2. é‡æ–°åˆ†é…ä»»åŠ¡
        self.event_bus.publish("task.reassign", {
            "node_id": node_id
        })
        
        self.logger.warning("Node marked as unhealthy: %s", node_id)

class NodeRegistry:
    """èŠ‚ç‚¹æ³¨å†Œè¡¨ï¼Œå­˜å‚¨èŠ‚ç‚¹ä¿¡æ¯"""
    
    def __init__(self, db: Database):
        self.db = db
        self.logger = logging.getLogger(__name__)
    
    def register_node(self, node_info: NodeInfo):
        """æ³¨å†ŒèŠ‚ç‚¹"""
        sql = """
        INSERT INTO crawler_nodes (
            id, cluster_id, name, description, 
            ip_address, port, node_type, 
            capabilities, resources, 
            status, last_heartbeat, 
            created_at, updated_at
        ) VALUES (
            %(id)s, %(cluster_id)s, %(name)s, %(description)s,
            %(ip_address)s, %(port)s, %(node_type)s,
            %(capabilities)s, %(resources)s,
            %(status)s, %(last_heartbeat)s,
            %(created_at)s, %(updated_at)s
        )
        """
        
        self.db.execute(sql, {
            "id": node_info.id,
            "cluster_id": node_info.cluster_id,
            "name": node_info.name,
            "description": node_info.description,
            "ip_address": node_info.ip_address,
            "port": node_info.port,
            "node_type": node_info.node_type,
            "capabilities": json.dumps(node_info.capabilities),
            "resources": json.dumps(node_info.resources),
            "status": node_info.status,
            "last_heartbeat": datetime.fromtimestamp(node_info.last_heartbeat),
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow()
        })
    
    def update_node(self, node_info: NodeInfo):
        """æ›´æ–°èŠ‚ç‚¹ä¿¡æ¯"""
        sql = """
        UPDATE crawler_nodes SET
            name = %(name)s,
            description = %(description)s,
            capabilities = %(capabilities)s,
            resources = %(resources)s,
            status = %(status)s,
            last_heartbeat = %(last_heartbeat)s,
            updated_at = %(updated_at)s
        WHERE id = %(id)s
        """
        
        self.db.execute(sql, {
            "id": node_info.id,
            "name": node_info.name,
            "description": node_info.description,
            "capabilities": json.dumps(node_info.capabilities),
            "resources": json.dumps(node_info.resources),
            "status": node_info.status,
            "last_heartbeat": datetime.fromtimestamp(node_info.last_heartbeat),
            "updated_at": datetime.utcnow()
        })
    
    def get_node(self, node_id: str) -> Optional[NodeInfo]:
        """è·å–èŠ‚ç‚¹ä¿¡æ¯"""
        sql = "SELECT * FROM crawler_nodes WHERE id = %(id)s"
        row = self.db.fetchone(sql, {"id": node_id})
        return self._row_to_node(row) if row else None
    
    def get_all_nodes(self) -> List[NodeInfo]:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹"""
        sql = "SELECT * FROM crawler_nodes"
        rows = self.db.fetchall(sql)
        return [self._row_to_node(row) for row in rows]
    
    def get_nodes_by_status(self, status: str) -> List[NodeInfo]:
        """è·å–ç‰¹å®šçŠ¶æ€çš„èŠ‚ç‚¹"""
        sql = "SELECT * FROM crawler_nodes WHERE status = %(status)s"
        rows = self.db.fetchall(sql, {"status": status})
        return [self._row_to_node(row) for row in rows]
    
    def _row_to_node(self, row: Dict) -> NodeInfo:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸ºNodeInfoå¯¹è±¡"""
        return NodeInfo(
            id=row["id"],
            cluster_id=row["cluster_id"],
            name=row["name"],
            description=row["description"],
            ip_address=row["ip_address"],
            port=row["port"],
            node_type=row["node_type"],
            capabilities=json.loads(row["capabilities"]),
            resources=json.loads(row["resources"]),
            status=row["status"],
            last_heartbeat=row["last_heartbeat"].timestamp(),
            health=NodeHealthStatus(
                status=row["health_status"],
                details=json.loads(row["health_details"]) if row["health_details"] else {},
                timestamp=row["health_timestamp"]
            ) if row["health_status"] else NodeHealthStatus(status="unknown"),
            created_at=row["created_at"],
            updated_at=row["updated_at"]
        )

class NodeHealthChecker:
    """èŠ‚ç‚¹å¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self, config: Config):
        self.config = config
        self.logger = logging.getLogger(__name__)
    
    def check(self, node_id: str) -> NodeHealthStatus:
        """
        æ£€æŸ¥èŠ‚ç‚¹å¥åº·çŠ¶æ€
        
        :param node_id: èŠ‚ç‚¹ID
        :return: å¥åº·çŠ¶æ€
        """
        # 1. æ£€æŸ¥åŸºç¡€è¿é€šæ€§
        if not self._check_connectivity(node_id):
            return NodeHealthStatus(
                status="unreachable",
                details={"error": "Node is unreachable"},
                timestamp=datetime.utcnow()
            )
        
        # 2. æ£€æŸ¥èµ„æºä½¿ç”¨
        resource_status = self._check_resources(node_id)
        
        # 3. æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œ
        task_status = self._check_tasks(node_id)
        
        # 4. ç»¼åˆå¥åº·çŠ¶æ€
        return self._determine_overall_status(resource_status, task_status)
    
    def _check_connectivity(self, node_id: str) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹è¿é€šæ€§"""
        # å®ç°èŠ‚ç‚¹è¿é€šæ€§æ£€æŸ¥
        # è¿™é‡Œç®€åŒ–ä¸ºè¿”å›True
        return True
    
    def _check_resources(self, node_id: str) -> Dict:
        """æ£€æŸ¥èµ„æºä½¿ç”¨"""
        # å®ç°èµ„æºæ£€æŸ¥
        # è¿™é‡Œç®€åŒ–ä¸ºè¿”å›ç¤ºä¾‹æ•°æ®
        return {
            "cpu_usage": 0.65,
            "memory_usage": 0.75,
            "network_io": 120.5,
            "disk_io": 45.2
        }
    
    def _check_tasks(self, node_id: str) -> Dict:
        """æ£€æŸ¥ä»»åŠ¡æ‰§è¡Œ"""
        # å®ç°ä»»åŠ¡æ£€æŸ¥
        # è¿™é‡Œç®€åŒ–ä¸ºè¿”å›ç¤ºä¾‹æ•°æ®
        return {
            "task_count": 5,
            "task_errors": 0,
            "task_latency": 1.2
        }
    
    def _determine_overall_status(
        self,
        resource_status: Dict,
        task_status: Dict
    ) -> NodeHealthStatus:
        """ç¡®å®šæ•´ä½“å¥åº·çŠ¶æ€"""
        # 1. æª¢æŸ¥èµ„æºä½¿ç”¨æ˜¯å¦è¶…æ ‡
        if resource_status["cpu_usage"] > 0.9 or resource_status["memory_usage"] > 0.95:
            return NodeHealthStatus(
                status="unhealthy",
                details={
                    "reason": "High resource usage",
                    "cpu": resource_status["cpu_usage"],
                    "memory": resource_status["memory_usage"]
                },
                timestamp=datetime.utcnow()
            )
        
        # 2. æª¢æŸ¥ä»»åŠ¡é”™è¯¯ç‡
        if task_status["task_errors"] > 0:
            return NodeHealthStatus(
                status="degraded",
                details={
                    "reason": "Task errors detected",
                    "error_count": task_status["task_errors"]
                },
                timestamp=datetime.utcnow()
            )
        
        # 3. æª¢æŸ¥ä»»åŠ¡å»¶è¿Ÿ
        if task_status["task_latency"] > 5.0:
            return NodeHealthStatus(
                status="degraded",
                details={
                    "reason": "High task latency",
                    "latency": task_status["task_latency"]
                },
                timestamp=datetime.utcnow()
            )
        
        # 4. å¥åº·çŠ¶æ€
        return NodeHealthStatus(
            status="healthy",
            details={
                "cpu_usage": resource_status["cpu_usage"],
                "memory_usage": resource_status["memory_usage"],
                "task_count": task_status["task_count"]
            },
            timestamp=datetime.utcnow()
        )

# è¾…åŠ©ç±»å®šä¹‰
class NodeInfo:
    """èŠ‚ç‚¹ä¿¡æ¯"""
    def __init__(
        self,
        id: str,
        cluster_id: str,
        name: str,
        description: str,
        ip_address: str,
        port: int,
        node_type: str,
        capabilities: Dict,
        resources: Dict,
        status: str,
        last_heartbeat: float,
        health: NodeHealthStatus,
        created_at: datetime,
        updated_at: datetime
    ):
        self.id = id
        self.cluster_id = cluster_id
        self.name = name
        self.description = description
        self.ip_address = ip_address
        self.port = port
        self.node_type = node_type
        self.capabilities = capabilities
        self.resources = resources
        self.status = status
        self.last_heartbeat = last_heartbeat
        self.health = health
        self.created_at = created_at
        self.updated_at = updated_at
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "id": self.id,
            "cluster_id": self.cluster_id,
            "name": self.name,
            "description": self.description,
            "ip_address": self.ip_address,
            "port": self.port,
            "node_type": self.node_type,
            "capabilities": self.capabilities,
            "resources": self.resources,
            "status": self.status,
            "last_heartbeat": self.last_heartbeat,
            "health": self.health.to_dict(),
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None
        }

class NodeHealthStatus:
    """èŠ‚ç‚¹å¥åº·çŠ¶æ€"""
    def __init__(
        self,
        status: str,
        details: Dict = None,
        timestamp: datetime = None
    ):
        self.status = status
        self.details = details or {}
        self.timestamp = timestamp or datetime.utcnow()
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "status": self.status,
            "details": self.details,
            "timestamp": self.timestamp.isoformat()
        }

class NodeHeartbeat:
    """èŠ‚ç‚¹å¿ƒè·³"""
    def __init__(
        self,
        node_id: str,
        timestamp: float,
        resources: Dict,
        load: float,
        active_tasks: List[str]
    ):
        self.node_id = node_id
        self.timestamp = timestamp
        self.resources = resources
        self.load = load
        self.active_tasks = active_tasks
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "node_id": self.node_id,
            "timestamp": self.timestamp,
            "resources": self.resources,
            "load": self.load,
            "active_tasks": self.active_tasks
        }

class NodeRegistrationResult:
    """èŠ‚ç‚¹æ³¨å†Œç»“æœ"""
    def __init__(
        self,
        node_id: str,
        registration_time: float,
        initial_status: str
    ):
        self.node_id = node_id
        self.registration_time = registration_time
        self.initial_status = initial_status
```

#### 8.4.2 ä»»åŠ¡è°ƒåº¦å™¨

**æŠ€æœ¯å®ç°ï¼š**
```python
import heapq
import time
import logging
from typing import Dict, List, Optional, Set
import threading

class TaskScheduler:
    """ä»»åŠ¡è°ƒåº¦å™¨ï¼Œè´Ÿè´£çˆ¬è™«ä»»åŠ¡çš„åˆ†é…å’Œè°ƒåº¦"""
    
    def __init__(
        self,
        config: Config,
        node_manager: CrawlerNodeManager,
        task_queue: TaskQueue,
        event_bus: EventBus
    ):
        self.config = config
        self.node_manager = node_manager
        self.task_queue = task_queue
        self.event_bus = event_bus
        self.logger = logging.getLogger(__name__)
        self.running = False
        self.scheduler_thread = None
        self.lock = threading.Lock()
        self.assigned_tasks = {}  # task_id -> node_id
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.running:
            return
        
        self.running = True
        self.logger.info("Starting task scheduler")
        
        # å¯åŠ¨è°ƒåº¦çº¿ç¨‹
        self.scheduler_thread = threading.Thread(
            target=self._schedule_loop,
            daemon=True
        )
        self.scheduler_thread.start()
        
        self.logger.info("Task scheduler started")
    
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if not self.running:
            return
        
        self.running = False
        self.logger.info("Stopping task scheduler")
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5.0)
        
        self.logger.info("Task scheduler stopped")
    
    def _schedule_loop(self):
        """è°ƒåº¦å¾ªç¯"""
        while self.running:
            try:
                # 1. è·å–å¯ç”¨èŠ‚ç‚¹
                online_nodes = self.node_manager.get_nodes_by_status("online")
                if not online_nodes:
                    time.sleep(self.config.schedule_interval)
                    continue
                
                # 2. è·å–å¾…è°ƒåº¦ä»»åŠ¡
                tasks = self.task_queue.get_pending_tasks(
                    limit=self.config.max_tasks_per_schedule
                )
                if not tasks:
                    time.sleep(self.config.schedule_interval)
                    continue
                
                # 3. ä¸ºæ¯ä¸ªä»»åŠ¡é€‰æ‹©åˆé€‚çš„èŠ‚ç‚¹
                for task in tasks:
                    node_id = self._select_node(task, online_nodes)
                    if node_id:
                        # åˆ†é…ä»»åŠ¡
                        self._assign_task(task, node_id)
                    else:
                        # æ²¡æœ‰åˆé€‚çš„èŠ‚ç‚¹ï¼Œç¨åé‡è¯•
                        self.logger.debug(
                            "No suitable node for task %s, will retry later", 
                            task.id
                        )
                
                # 4. ç­‰å¾…ä¸‹ä¸€æ¬¡è°ƒåº¦
                time.sleep(self.config.schedule_interval)
                
            except Exception as e:
                self.logger.error("Error in scheduling loop: %s", str(e))
                time.sleep(1)
    
    def _select_node(
        self,
        task: CrawlerTask,
        online_nodes: List[NodeInfo]
    ) -> Optional[str]:
        """é€‰æ‹©æœ€é€‚åˆçš„èŠ‚ç‚¹"""
        # 1. è¿‡æ»¤ä¸æ”¯æŒä»»åŠ¡ç±»å‹çš„èŠ‚ç‚¹
        compatible_nodes = [
            node for node in online_nodes
            if self._is_node_compatible(node, task)
        ]
        if not compatible_nodes:
            return None
        
        # 2. åº”ç”¨è°ƒåº¦ç­–ç•¥
        strategy = task.schedule_strategy or self.config.default_schedule_strategy
        if strategy == "least_loaded":
            return self._select_least_loaded_node(compatible_nodes)
        elif strategy == "geo_location":
            return self._select_geo_location_node(compatible_nodes, task)
        elif strategy == "content_based":
            return self._select_content_based_node(compatible_nodes, task)
        
        # é»˜è®¤ç­–ç•¥ï¼šæœ€å°è´Ÿè½½
        return self._select_least_loaded_node(compatible_nodes)
    
    def _is_node_compatible(
        self,
        node: NodeInfo,
        task: CrawlerTask
    ) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æ”¯æŒä»»åŠ¡"""
        # 1. æª¢æŸ¥èŠ‚ç‚¹ç±»å‹
        if task.node_type and node.node_type != task.node_type:
            return False
        
        # 2. æª¢æŸ¥èƒ½åŠ›è¦æ±‚
        for capability, required in task.capabilities.items():
            if capability not in node.capabilities or node.capabilities[capability] < required:
                return False
        
        # 3. æª¢æŸ¥èµ„æºè¦æ±‚
        if task.min_resources:
            for resource, required in task.min_resources.items():
                if resource not in node.resources or node.resources[resource] < required:
                    return False
        
        return True
    
    def _select_least_loaded_node(
        self,
        nodes: List[NodeInfo]
    ) -> Optional[str]:
        """é€‰æ‹©è´Ÿè½½æœ€å°çš„èŠ‚ç‚¹"""
        if not nodes:
            return None
        
        # æŒ‰è´Ÿè½½æ’åºï¼ˆå‡åºï¼‰
        sorted_nodes = sorted(nodes, key=lambda n: n.load)
        return sorted_nodes[0].id
    
    def _select_geo_location_node(
        self,
        nodes: List[NodeInfo],
        task: CrawlerTask
    ) -> Optional[str]:
        """é€‰æ‹©åœ°ç†ä½ç½®æœ€è¿‘çš„èŠ‚ç‚¹"""
        if not task.target_region or not nodes:
            return self._select_least_loaded_node(nodes)
        
        # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹ä¸ç›®æ ‡åŒºåŸŸçš„è·ç¦»
        node_distances = []
        for node in nodes:
            distance = self._calculate_geo_distance(node.region, task.target_region)
            node_distances.append((distance, node))
        
        # æŒ‰è·ç¦»æ’åº
        sorted_nodes = sorted(node_distances, key=lambda x: x[0])
        return sorted_nodes[0][1].id
    
    def _calculate_geo_distance(
        self,
        node_region: str,
        target_region: str
    ) -> float:
        """è®¡ç®—åœ°ç†ä½ç½®è·ç¦»"""
        # ç®€å•å®ç°ï¼šåŸºäºåŒºåŸŸä»£ç çš„åŒ¹é…
        if node_region == target_region:
            return 0.0
        elif node_region[:2] == target_region[:2]:  # åŒä¸€å›½å®¶
            return 1.0
        else:
            return 2.0
    
    def _select_content_based_node(
        self,
        nodes: List[NodeInfo],
        task: CrawlerTask
    ) -> Optional[str]:
        """é€‰æ‹©åŸºäºå†…å®¹ç‰¹æ€§çš„èŠ‚ç‚¹"""
        if not task.content_features or not nodes:
            return self._select_least_loaded_node(nodes)
        
        # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹ä¸å†…å®¹ç‰¹å¾çš„åŒ¹é…åº¦
        node_matches = []
        for node in nodes:
            match_score = self._calculate_content_match(node, task.content_features)
            node_matches.append((match_score, node))
        
        # æŒ‰åŒ¹é…åº¦æ’åºï¼ˆé™åºï¼‰
        sorted_nodes = sorted(node_matches, key=lambda x: x[0], reverse=True)
        return sorted_nodes[0][1].id
    
    def _calculate_content_match(
        self,
        node: NodeInfo,
        content_features: Dict
    ) -> float:
        """è®¡ç®—å†…å®¹åŒ¹é…åº¦"""
        score = 0.0
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æ”¯æŒå†…å®¹ç±»å‹
        if "content_type" in content_features:
            if content_features["content_type"] in node.capabilities.get("content_types", []):
                score += 0.4
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æ”¯æŒç‰¹å®šæŠ€æœ¯
        if "technology" in content_features:
            if content_features["technology"] in node.capabilities.get("technologies", []):
                score += 0.3
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å¤„ç†è¿‡ç±»ä¼¼å†…å®¹
        if "similarity" in content_features:
            score += content_features["similarity"] * 0.3
        
        return score
    
    def _assign_task(
        self,
        task: CrawlerTask,
        node_id: str
    ):
        """åˆ†é…ä»»åŠ¡åˆ°èŠ‚ç‚¹"""
        with self.lock:
            # 1. æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task.status = "assigned"
            task.assigned_node = node_id
            task.assigned_at = time.time()
            self.task_queue.update_task(task)
            
            # 2. è®°å½•åˆ†é…
            self.assigned_tasks[task.id] = node_id
            
            # 3. å‘å¸ƒäº‹ä»¶
            self.event_bus.publish("task.assigned", {
                "task_id": task.id,
                "node_id": node_id,
                "task_info": task.to_dict()
            })
            
            self.logger.info("Task %s assigned to node %s", task.id, node_id)
    
    def handle_task_completion(
        self,
        task_id: str,
        node_id: str,
        result: TaskResult
    ):
        """
        å¤„ç†ä»»åŠ¡å®Œæˆ
        
        :param task_id: ä»»åŠ¡ID
        :param node_id: èŠ‚ç‚¹ID
        :param result: ä»»åŠ¡ç»“æœ
        """
        with self.lock:
            # 1. ç§»é™¤åˆ†é…è®°å½•
            if task_id in self.assigned_tasks:
                del self.assigned_tasks[task_id]
            
            # 2. æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task = self.task_queue.get_task(task_id)
            if not task:
                self.logger.warning("Task %s not found for completion", task_id)
                return
            
            task.status = "completed" if result.success else "failed"
            task.completed_at = time.time()
            task.result = result.to_dict()
            self.task_queue.update_task(task)
            
            # 3. å‘å¸ƒäº‹ä»¶
            event_type = "task.completed" if result.success else "task.failed"
            self.event_bus.publish(event_type, {
                "task_id": task_id,
                "node_id": node_id,
                "result": result.to_dict()
            })
            
            self.logger.info(
                "Task %s %s by node %s", 
                task_id, 
                "completed" if result.success else "failed",
                node_id
            )
    
    def handle_task_timeout(
        self,
        task_id: str,
        node_id: str
    ):
        """
        å¤„ç†ä»»åŠ¡è¶…æ—¶
        
        :param task_id: ä»»åŠ¡ID
        :param node_id: èŠ‚ç‚¹ID
        """
        with self.lock:
            # 1. ç§»é™¤åˆ†é…è®°å½•
            if task_id in self.assigned_tasks:
                del self.assigned_tasks[task_id]
            
            # 2. æ›´æ–°ä»»åŠ¡çŠ¶æ€
            task = self.task_queue.get_task(task_id)
            if not task:
                self.logger.warning("Task %s not found for timeout", task_id)
                return
            
            task.status = "timeout"
            task.completed_at = time.time()
            self.task_queue.update_task(task)
            
            # 3. é‡æ–°å…¥é˜Ÿï¼ˆå¦‚æœéœ€è¦é‡è¯•ï¼‰
            if task.retry_count < task.max_retries:
                task.retry_count += 1
                task.status = "pending"
                task.assigned_node = None
                self.task_queue.add_task(task)
                
                self.logger.info(
                    "Task %s timed out, retrying (attempt %d/%d)", 
                    task_id, 
                    task.retry_count,
                    task.max_retries
                )
            else:
                self.logger.warning(
                    "Task %s timed out and exceeded max retries", 
                    task_id
                )
            
            # 4. å‘å¸ƒäº‹ä»¶
            self.event_bus.publish("task.timeout", {
                "task_id": task_id,
                "node_id": node_id,
                "retry_count": task.retry_count
            })

class TaskQueue:
    """ä»»åŠ¡é˜Ÿåˆ—ï¼Œç®¡ç†å¾…å¤„ç†ä»»åŠ¡"""
    
    def __init__(self, db: Database):
        self.db = db
        self.logger = logging.getLogger(__name__)
    
    def add_task(self, task: CrawlerTask):
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        sql = """
        INSERT INTO crawler_tasks (
            id, project_id, workflow_id, task_type,
            parameters, priority, 
            min_resources, capabilities,
            schedule_strategy, target_region, content_features,
            status, created_at, updated_at
        ) VALUES (
            %(id)s, %(project_id)s, %(workflow_id)s, %(task_type)s,
            %(parameters)s, %(priority)s,
            %(min_resources)s, %(capabilities)s,
            %(schedule_strategy)s, %(target_region)s, %(content_features)s,
            %(status)s, %(created_at)s, %(updated_at)s
        )
        """
        
        self.db.execute(sql, {
            "id": task.id,
            "project_id": task.project_id,
            "workflow_id": task.workflow_id,
            "task_type": task.task_type,
            "parameters": json.dumps(task.parameters),
            "priority": task.priority,
            "min_resources": json.dumps(task.min_resources) if task.min_resources else None,
            "capabilities": json.dumps(task.capabilities) if task.capabilities else None,
            "schedule_strategy": task.schedule_strategy,
            "target_region": task.target_region,
            "content_features": json.dumps(task.content_features) if task.content_features else None,
            "status": task.status,
            "created_at": task.created_at,
            "updated_at": task.updated_at
        })
    
    def get_pending_tasks(
        self,
        limit: int = 100
    ) -> List[CrawlerTask]:
        """è·å–å¾…å¤„ç†ä»»åŠ¡"""
        sql = """
        SELECT * FROM crawler_tasks 
        WHERE status = 'pending'
        ORDER BY priority DESC, created_at
        LIMIT %(limit)s
        """
        
        rows = self.db.fetchall(sql, {"limit": limit})
        return [self._row_to_task(row) for row in rows]
    
    def get_task(self, task_id: str) -> Optional[CrawlerTask]:
        """è·å–ä»»åŠ¡è¯¦æƒ…"""
        sql = "SELECT * FROM crawler_tasks WHERE id = %(id)s"
        row = self.db.fetchone(sql, {"id": task_id})
        return self._row_to_task(row) if row else None
    
    def update_task(self, task: CrawlerTask):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        sql = """
        UPDATE crawler_tasks SET
            status = %(status)s,
            assigned_node = %(assigned_node)s,
            assigned_at = %(assigned_at)s,
            completed_at = %(completed_at)s,
            result = %(result)s,
            retry_count = %(retry_count)s,
            updated_at = %(updated_at)s
        WHERE id = %(id)s
        """
        
        self.db.execute(sql, {
            "id": task.id,
            "status": task.status,
            "assigned_node": task.assigned_node,
            "assigned_at": datetime.fromtimestamp(task.assigned_at) if task.assigned_at else None,
            "completed_at": datetime.fromtimestamp(task.completed_at) if task.completed_at else None,
            "result": json.dumps(task.result) if task.result else None,
            "retry_count": task.retry_count,
            "updated_at": datetime.utcnow()
        })

# è¾…åŠ©ç±»å®šä¹‰
class CrawlerTask:
    """çˆ¬è™«ä»»åŠ¡"""
    def __init__(
        self,
        id: str,
        project_id: str,
        workflow_id: str,
        task_type: str,
        parameters: Dict,
        priority: int = 5,
        min_resources: Optional[Dict] = None,
        capabilities: Optional[Dict] = None,
        schedule_strategy: Optional[str] = None,
        target_region: Optional[str] = None,
        content_features: Optional[Dict] = None,
        status: str = "pending",
        created_at: datetime = None,
        updated_at: datetime = None,
        assigned_node: Optional[str] = None,
        assigned_at: Optional[float] = None,
        completed_at: Optional[float] = None,
        result: Optional[Dict] = None,
        retry_count: int = 0,
        max_retries: int = 3
    ):
        self.id = id
        self.project_id = project_id
        self.workflow_id = workflow_id
        self.task_type = task_type
        self.parameters = parameters
        self.priority = priority
        self.min_resources = min_resources or {}
        self.capabilities = capabilities or {}
        self.schedule_strategy = schedule_strategy
        self.target_region = target_region
        self.content_features = content_features or {}
        self.status = status
        self.created_at = created_at or datetime.utcnow()
        self.updated_at = updated_at or datetime.utcnow()
        self.assigned_node = assigned_node
        self.assigned_at = assigned_at
        self.completed_at = completed_at
        self.result = result
        self.retry_count = retry_count
        self.max_retries = max_retries
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "id": self.id,
            "project_id": self.project_id,
            "workflow_id": self.workflow_id,
            "task_type": self.task_type,
            "parameters": self.parameters,
            "priority": self.priority,
            "min_resources": self.min_resources,
            "capabilities": self.capabilities,
            "schedule_strategy": self.schedule_strategy,
            "target_region": self.target_region,
            "content_features": self.content_features,
            "status": self.status,
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat(),
            "assigned_node": self.assigned_node,
            "assigned_at": self.assigned_at,
            "completed_at": self.completed_at,
            "result": self.result,
            "retry_count": self.retry_count,
            "max_retries": self.max_retries
        }

class TaskResult:
    """ä»»åŠ¡ç»“æœ"""
    def __init__(
        self,
        success: bool,
        data: Optional[Dict] = None,
        error: Optional[str] = None,
        metrics: Optional[Dict] = None
    ):
        self.success = success
        self.data = data or {}
        self.error = error
        self.metrics = metrics or {}
        self.timestamp = datetime.utcnow()
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "success": self.success,
            "data": self.data,
            "error": self.error,
            "metrics": self.metrics,
            "timestamp": self.timestamp.isoformat()
        }
```

---

## ğŸ“‘ ç›¸å…³ç« èŠ‚

| å‰åº | å½“å‰ | åç»­ |
|-----|------|------|
| [8.3](ch8-3.md) | **8.4** | [8.5](ch8-5.md) |

**å¿«é€Ÿé“¾æ¥ï¼š**
- [â† è¿”å›ç¬¬8ç« é¦–é ](ch8-index.md)
