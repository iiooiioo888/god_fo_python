<!-- LEGACY FILE NOTICE -->
> ⚠️ 此檔案為舊版備份，已被新檔取代： [ch9-6-API详细规范.md](ch9-6-API详细规范.md)\n> 備份時間：2025-10-31 12:28:27\n
---

**[← 返回第9章首頁](ch9-index.md)**

---

### 9.6 性能测试方案

#### 9.6.1 基準测试场景

1. **数据源注册中心性能测试**
   ```python
   # dsr_load_test.py
   import os
   import time
   import json
   import random
   from locust import HttpUser, task, between, events
   from locust.runners import MasterRunner
   
   # 测试配置
   TEST_DATA_SOURCES = [
       {
           "name": f"test-source-{i}",
           "display_name": f"Test Source {i}",
           "url": f"https://example.com/data/{i}",
           "category": random.choice(["web", "api", "social"]),
           "data_type": random.choice(["html", "json", "xml"]),
           "tags": ["test", "performance"]
       } for i in range(1000)
   ]
   
   @events.test_start.add_listener
   def on_test_start(environment, **kwargs):
       """测试开始前的准备工作"""
       if not isinstance(environment.runner, MasterRunner):
           print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Starting DSR performance test")
           print(f"  * Test data sources: {len(TEST_DATA_SOURCES)}")
           print(f"  * Target RPS: {environment.parsed_options.spawn_rate}")
   
   class DataSourcesUser(HttpUser):
       wait_time = between(0.1, 0.5)
       
       def on_start(self):
           """用户启动时的初始化"""
           self.auth_token = self._get_auth_token()
           self.headers = {
               "Authorization": f"Bearer {self.auth_token}",
               "Content-Type": "application/json"
           }
       
       def _get_auth_token(self):
           """获取认证令牌"""
           response = self.client.post(
               "/api/v1/auth/token",
               json={
                   "client_id": "performance-test",
                   "client_secret": "perf-test-secret",
                   "grant_type": "client_credentials"
               }
           )
           return response.json()["access_token"]
       
       @task(5)
       def list_data_sources(self):
           """列出数据源"""
           self.client.get(
               "/api/v1/data-sources",
               headers=self.headers,
               name="/api/v1/data-sources"
           )
       
       @task(3)
       def get_data_source(self):
           """获取单个数据源"""
           source_id = f"ds-{random.randint(1, 1000):04d}"
           self.client.get(
               f"/api/v1/data-sources/{source_id}",
               headers=self.headers,
               name="/api/v1/data-sources/{id}"
           )
       
       @task(2)
       def create_data_source(self):
           """创建数据源"""
           source = random.choice(TEST_DATA_SOURCES)
           self.client.post(
               "/api/v1/data-sources",
               json=source,
               headers=self.headers,
               name="/api/v1/data-sources"
           )
       
       @task(1)
       def search_data_sources(self):
           """搜索数据源"""
           query = random.choice(["test", "example", "api", "web"])
           self.client.get(
               f"/api/v1/data-sources?search={query}",
               headers=self.headers,
               name="/api/v1/data-sources:search"
           )
   ```

2. **分布式爬虫集群性能测试**
   ```python
   # crawler_cluster_load_test.py
   import os
   import time
   import json
   import random
   from locust import HttpUser, task, between, events
   from locust.runners import MasterRunner
   
   # 测试配置
   TEST_TASKS = [
       {
           "task_type": "web_crawl",
           "parameters": {
               "url": f"https://example.com/page/{i}",
               "depth": random.randint(1, 3)
           },
           "priority": random.randint(1, 10),
           "min_resources": {
               "memory_mb": random.choice([512, 1024, 2048]),
               "cpu_cores": random.uniform(0.5, 2.0)
           }
       } for i in range(10000)
   ]
   
   class CrawlerUser(HttpUser):
       wait_time = between(0.01, 0.1)
       
       def on_start(self):
           """用户启动时的初始化"""
           self.auth_token = self._get_auth_token()
           self.headers = {
               "Authorization": f"Bearer {self.auth_token}",
               "Content-Type": "application/json"
           }
       
       def _get_auth_token(self):
           """获取认证令牌"""
           response = self.client.post(
               "/api/v1/auth/token",
               json={
                   "client_id": "crawler-test",
                   "client_secret": "crawler-test-secret",
                   "grant_type": "client_credentials"
               }
           )
           return response.json()["access_token"]
       
       @task(10)
       def create_task(self):
           """创建爬虫任务"""
           task = random.choice(TEST_TASKS)
           response = self.client.post(
               "/api/v1/tasks",
               json=task,
               headers=self.headers,
               name="/api/v1/tasks"
           )
           
           if response.status_code == 201:
               task_id = response.json()["id"]
               # 轮询任务状态
               for _ in range(10):
                   time.sleep(0.1)
                   status_response = self.client.get(
                       f"/api/v1/tasks/{task_id}",
                       headers=self.headers,
                       name="/api/v1/tasks/{id}"
                   )
                   
                   if status_response.status_code == 200:
                       status = status_response.json()["status"]
                       if status in ["completed", "failed"]:
                           break
   ```

#### 9.6.2 性能指标阈值

1. **API性能指标阈值**
   | 指标 | 95分位 | 99分位 | 错误率 | 资源使用 |
   |------|--------|--------|--------|----------|
   | **数据源注册中心** | | | | |
   | 列建数据源 | <200ms | <500ms | <0.1% | CPU<50%, Mem<70% |
   | 获取数据源列表 | <100ms | <300ms | <0.1% | CPU<40%, Mem<60% |
   | 搜索数据源 | <150ms | <400ms | <0.1% | CPU<45%, Mem<65% |
   | **分布式爬虫集群** | | | | |
   | 创建爬虫任务 | <100ms | <300ms | <0.1% | CPU<50%, Mem<70% |
   | 任务状态查询 | <50ms | <200ms | <0.1% | CPU<30%, Mem<50% |
   | 节点心跳 | <20ms | <100ms | <0.01% | CPU<20%, Mem<40% |

2. **系统容量规划**
   | 服务 | 单例配置 | 单例数量 | 支持QPS | 每日任务量 | 存储需求 |
   |------|----------|----------|---------|------------|----------|
   | 数据源注册中心 | 2vCPU, 4GB | 3 | 1,000 | - | 50GB |
   | 网站指纹分析引擎 | 4vCPU, 8GB | 5 | 500 | - | 200GB |
   | 数据源健康监测系统 | 2vCPU, 4GB | 3 | 2,000 | - | 100GB |
   | 数据处理工作流引擎 | 4vCPU, 8GB | 5 | 1,500 | - | 150GB |
   | 自动化媒体处理管道 | 8vCPU, 16GB, 1GPU | 10 | 100 | 10,000 | 10TB |
   | AI辅助开发系统 | 4vCPU, 8GB | 3 | 300 | - | 50GB |
   | 数据合规与安全中心 | 2vCPU, 4GB | 3 | 500 | - | 75GB |
   | 分布式爬虫集群管理系统 | 4vCPU, 8GB | 5 | 2,000 | 1,000,000 | 200GB |

---

## 📑 相关章节

| 前序 | 当前 | 后续 |
|-----|------|------|
| [9.5](ch9-5.md) | **9.6** | [9.7](ch9-7.md) |

**快速链接：**
- [← 返回第9章首頁](ch9-index.md)
