<!-- LEGACY FILE NOTICE -->
> âš ï¸ æ­¤æª”æ¡ˆç‚ºèˆŠç‰ˆå‚™ä»½ï¼Œå·²è¢«æ–°æª”å–ä»£ï¼š [ch7-8-å®‰å…¨è€ƒè™‘.md](ch7-8-å®‰å…¨è€ƒè™‘.md)\n> å‚™ä»½æ™‚é–“ï¼š2025-10-31 12:28:26\n
---

**[â† è¿”å›ç¬¬7ç« é¦–é ](ch7-index.md)**

---

### 7.8 å®‰å…¨è€ƒè™‘

#### 7.8.1 æ•°æ®å®‰å…¨ç­–ç•¥

1. **åŸºäºå±æ€§çš„è®¿é—®æ§åˆ¶(PABC)**
   ```python
   class AttributeBasedAccessControl:
       """åŸºäºå±æ€§çš„è®¿é—®æ§åˆ¶"""
       
       def __init__(self, policy_engine: PolicyEngine):
           self.policy_engine = policy_engine
           self.logger = logging.getLogger(__name__)
       
       def check_access(
           self,
           user: User,
           resource: Resource,
           action: str
       ) -> bool:
           """
           æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®èµ„æº
           
           :param user: ç”¨æˆ·å¯¹è±¡
           :param resource: èµ„æºå¯¹è±¡
           :param action: æ“ä½œç±»å‹
           :return: æ˜¯å¦æœ‰æƒé™
           """
           # 1. æ„å»ºè¯·æ±‚ä¸Šä¸‹æ–‡
           context = {
               "user": self._extract_user_attributes(user),
               "resource": self._extract_resource_attributes(resource),
               "action": action,
               "environment": self._get_environment_attributes()
           }
           
           # 2. è¯„ä¼°ç­–ç•¥
           decision = self.policy_engine.evaluate(context)
           
           # 3. è®°å½•å®¡è®¡æ—¥å¿—
           self._log_audit(user, resource, action, decision)
           
           return decision == "permit"
       
       def _extract_user_attributes(self, user: User) -> Dict:
           """æå–ç”¨æˆ·å±æ€§"""
           return {
               "id": user.id,
               "roles": user.roles,
               "department": user.department,
               "clearance_level": user.clearance_level,
               "region": user.region
           }
       
       def _extract_resource_attributes(self, resource: Resource) -> Dict:
           """æå–èµ„æºå±æ€§"""
           if isinstance(resource, DataSource):
               return {
                   "type": "data_source",
                   "category": resource.category,
                   "data_type": resource.data_type,
                   "region": self._determine_region(resource),
                   "sensitivity": self._determine_sensitivity(resource)
               }
           # å…¶ä»–èµ„æºç±»å‹...
           return {}
       
       def _determine_region(self, data_source: DataSource) -> str:
           """ç¡®å®šæ•°æ®æºæ‰€åœ¨åœ°åŒº"""
           # å®ç°åœ°åŒºæ£€æµ‹é€»è¾‘
           pass
       
       def _determine_sensitivity(self, data_source: DataSource) -> str:
           """ç¡®å®šæ•°æ®æ•æ„Ÿåº¦"""
           # å®ç°æ•æ„Ÿåº¦è¯„ä¼°
           pass
       
       def _get_environment_attributes(self) -> Dict:
           """è·å–ç¯å¢ƒå±æ€§"""
           return {
               "time": datetime.utcnow(),
               "ip_address": get_current_ip(),
               "device_type": get_device_type()
           }
       
       def _log_audit(
           self,
           user: User,
           resource: Resource,
           action: str,
           decision: str
       ):
           """è®°å½•å®¡è®¡æ—¥å¿—"""
           # å®ç°å®¡è®¡æ—¥å¿—è®°å½•
           pass
   ```

2. **æ•°æ®è„±æ•ç­–ç•¥å¼•æ“**
   ```python
   class DataRedactionEngine:
       """æ•°æ®è„±æ•ç­–ç•¥å¼•æ“"""
       
       def __init__(
           self,
           policy_repository: RedactionPolicyRepository,
           config: Config
       ):
           self.policy_repository = policy_repository
           self.config = config
           self.logger = logging.getLogger(__name__)
       
       def redact(
           self,
           data: Any,
           context: Dict
       ) -> Any:
           """
           è„±æ•æ•°æ®
           
           :param data: è¦è„±æ•çš„æ•°æ®
           :param context: ä¸Šä¸‹æ–‡ä¿¡æ¯
           :return: è„±æ•åçš„æ•°æ®
           """
           # 1. è·å–é€‚ç”¨çš„è„±æ•ç­–ç•¥
           policies = self._get_applicable_policies(context)
           
           # 2. åº”ç”¨è„±æ•ç­–ç•¥
           return self._apply_policies(data, policies)
       
       def _get_applicable_policies(self, context: Dict) -> List[RedactionPolicy]:
           """è·å–é€‚ç”¨çš„è„±æ•ç­–ç•¥"""
           return self.policy_repository.get_policies(
               data_types=context.get("data_types", []),
               regions=context.get("regions", []),
               sensitivity=context.get("sensitivity", "medium"),
               purpose=context.get("purpose", "processing")
           )
       
       def _apply_policies(
           self,
           data: Any,
           policies: List[RedactionPolicy]
       ) -> Any:
           """åº”ç”¨è„±æ•ç­–ç•¥"""
           if isinstance(data, str):
               return self._redact_string(data, policies)
           
           elif isinstance(data, dict):
               return {k: self._apply_policies(v, policies) for k, v in data.items()}
           
           elif isinstance(data, list):
               return [self._apply_policies(item, policies) for item in data]
           
           return data
       
       def _redact_string(self, text: str, policies: List[RedactionPolicy]) -> str:
           """è„±æ•å­—ç¬¦ä¸²"""
           result = text
           
           for policy in policies:
               for rule in policy.rules:
                   if rule.enabled:
                       result = re.sub(
                           rule.pattern,
                           self._get_replacement(rule, result),
                           result
                       )
           
           return result
       
       def _get_replacement(self, rule: RedactionRule, text: str) -> str:
           """è·å–æ›¿æ¢å­—ç¬¦ä¸²"""
           if rule.replacement_template == "hash":
               return hashlib.sha256(text.encode('utf-8')).hexdigest()[:8] + "..."
           elif rule.replacement_template == "mask":
               return "X" * len(text)
           elif rule.replacement_template.startswith("fixed:"):
               return rule.replacement_template.split(":", 1)[1]
           
           return rule.replacement_template
   ```

#### 7.8.2 åˆè§„æ€§å®¡è®¡

1. **å®¡è®¡æ—¥å¿—ç®¡ç†**
   ```sql
   -- åˆè§„æ€§å®¡è®¡æ—¥å¿—è¡¨
   CREATE TABLE compliance_audit_logs (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       user_id UUID REFERENCES users(id) ON DELETE SET NULL,
       project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
       action VARCHAR(50) NOT NULL,
       target_type VARCHAR(50) NOT NULL,
       target_id VARCHAR(255) NOT NULL,
       details JSONB,
       ip_address INET,
       user_agent TEXT,
       timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
       
       -- ç´¢å¼•
       INDEX idx_audit_user ON compliance_audit_logs(user_id),
       INDEX idx_audit_project ON compliance_audit_logs(project_id),
       INDEX idx_audit_action ON compliance_audit_logs(action),
       INDEX idx_audit_target ON compliance_audit_logs(target_type, target_id),
       INDEX idx_audit_timestamp ON compliance_audit_logs(timestamp DESC)
   );
   
   -- æ•°æ®è®¿é—®å®¡è®¡æ—¥å¿—è¡¨
   CREATE TABLE data_access_audit_logs (
       id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
       user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
       project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
       data_source_id UUID REFERENCES data_sources(id) ON DELETE SET NULL,
       access_type VARCHAR(20) NOT NULL,
       access_pattern VARCHAR(50) NOT NULL,
       data_categories JSONB NOT NULL,
       rows_accessed BIGINT NOT NULL,
       columns_accessed INT NOT NULL,
       sensitive_data_accessed BOOLEAN NOT NULL,
       ip_address INET NOT NULL,
       user_agent TEXT NOT NULL,
       timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
       
       -- ç´¢å¼•
       INDEX idx_data_access_user ON data_access_audit_logs(user_id),
       INDEX idx_data_access_data_source ON data_access_audit_logs(data_source_id),
       INDEX idx_data_access_timestamp ON data_access_audit_logs(timestamp DESC),
       INDEX idx_data_access_sensitive ON data_access_audit_logs(sensitive_data_accessed)
   );
   ```

2. **å®¡è®¡åˆ†ææœåŠ¡**
   ```python
   class AuditAnalysisService:
       """å®¡è®¡åˆ†ææœåŠ¡ï¼Œæ£€æµ‹å¼‚å¸¸è®¿é—®æ¨¡å¼"""
       
       def __init__(
           self,
           db: Database,
           config: Config
       ):
           self.db = db
           self.config = config
           self.logger = logging.getLogger(__name__)
       
       def analyze_access_patterns(
           self,
           user_id: str,
           time_window: timedelta = timedelta(days=7)
       ) -> AccessPatternAnalysis:
           """
           åˆ†æç”¨æˆ·è®¿é—®æ¨¡å¼
           
           :param user_id: ç”¨æˆ·ID
           :param time_window: åˆ†ææ—¶é—´çª—å£
           :return: è®¿é—®æ¨¡å¼åˆ†æç»“æœ
           """
           # 1. è·å–è®¿é—®æ—¥å¿—
           start_time = datetime.utcnow() - time_window
           access_logs = self._get_access_logs(user_id, start_time)
           
           # 2. åˆ†æè®¿é—®æ¨¡å¼
           pattern_analysis = self._analyze_patterns(access_logs)
           anomaly_detection = self._detect_anomalies(access_logs)
           
           # 3. ç”Ÿæˆé£é™©è¯„ä¼°
           risk_score = self._calculate_risk_score(pattern_analysis, anomaly_detection)
           
           return AccessPatternAnalysis(
               user_id=user_id,
               time_window=time_window,
               total_accesses=len(access_logs),
               pattern_analysis=pattern_analysis,
               anomaly_detection=anomaly_detection,
               risk_score=risk_score,
               timestamp=datetime.utcnow()
           )
       
       def _get_access_logs(
           self,
           user_id: str,
           start_time: datetime
       ) -> List[DataAccessLog]:
           """è·å–è®¿é—®æ—¥å¿—"""
           sql = """
           SELECT * FROM data_access_audit_logs 
           WHERE user_id = %(user_id)s AND timestamp >= %(start_time)s
           ORDER BY timestamp
           """
           
           rows = self.db.fetchall(sql, {
               "user_id": user_id,
               "start_time": start_time
           })
           
           return [self._row_to_log(row) for row in rows]
       
       def _analyze_patterns(self, access_logs: List[DataAccessLog]) -> Dict:
           """åˆ†æè®¿é—®æ¨¡å¼"""
           # 1. æŒ‰æ•°æ®æºåˆ†æ
           by_data_source = defaultdict(list)
           for log in access_logs:
               by_data_source[log.data_source_id].append(log)
           
           # 2. è®¡ç®—æ¯ä¸ªæ•°æ®æºçš„è®¿é—®é¢‘ç‡
           frequency = {}
           for ds_id, logs in by_data_source.items():
               time_diffs = [
                   (logs[i].timestamp - logs[i-1].timestamp).total_seconds()
                   for i in range(1, len(logs))
               ]
               
               frequency[ds_id] = {
                   "count": len(logs),
                   "avg_interval": sum(time_diffs) / len(time_diffs) if time_diffs else 0,
                   "sensitive_data_ratio": sum(1 for log in logs if log.sensitive_data_accessed) / len(logs)
               }
           
           # 3. è¯†åˆ«å¸¸ç”¨è®¿é—®æ¨¡å¼
           common_patterns = self._identify_common_patterns(access_logs)
           
           return {
               "by_data_source": frequency,
               "common_patterns": common_patterns,
               "time_of_day": self._analyze_time_patterns(access_logs)
           }
       
       def _identify_common_patterns(self, access_logs: List[DataAccessLog]) -> List[AccessPattern]:
           """è¯†åˆ«å¸¸ç”¨è®¿é—®æ¨¡å¼"""
           # ç®€å•å®ç°ï¼šåŸºäºè®¿é—®åºåˆ—
           sequences = []
           current_sequence = []
           
           for i, log in enumerate(access_logs):
               current_sequence.append(log.data_source_id)
               
               # å¦‚æœæ˜¯åºåˆ—ç»“æŸæˆ–è¾¾åˆ°æœ€å¤§é•¿åº¦
               if i == len(access_logs) - 1 or len(current_sequence) >= 5:
                   sequences.append(tuple(current_sequence))
                   current_sequence = []
           
           # ç»Ÿè®¡åºåˆ—é¢‘ç‡
           counter = Counter(sequences)
           return [
               AccessPattern(pattern=list(pattern), frequency=count)
               for pattern, count in counter.most_common(5)
           ]
       
       def _analyze_time_patterns(self, access_logs: List[DataAccessLog]) -> Dict:
           """åˆ†ææ—¶é—´æ¨¡å¼"""
           hour_counts = [0] * 24
           day_counts = [0] * 7  # 0=Monday, 6=Sunday
           
           for log in access_logs:
               hour_counts[log.timestamp.hour] += 1
               day_counts[log.timestamp.weekday()] += 1
           
           return {
               "by_hour": hour_counts,
               "by_day": day_counts
           }
       
       def _detect_anomalies(self, access_logs: List[DataAccessLog]) -> List[Anomaly]:
           """æ£€æµ‹å¼‚å¸¸è®¿é—®"""
           anomalies = []
           
           # 1. æ£€æµ‹éå¸¸è§„æ—¶é—´è®¿é—®
           off_hours = self._detect_off_hours_access(access_logs)
           if off_hours:
               anomalies.append(Anomaly(
                   type="off_hours",
                   description="æ£€æµ‹åˆ°éå¸¸è§„æ—¶é—´è®¿é—®",
                   severity="medium",
                   details={"count": len(off_hours), "times": [str(log.timestamp) for log in off_hours]}
               ))
           
           # 2. æ£€æµ‹æ•æ„Ÿæ•°æ®å¼‚å¸¸è®¿é—®
           sensitive_access = self._detect_sensitive_data_access(access_logs)
           if sensitive_access:
               anomalies.append(Anomaly(
                   type="sensitive_data",
                   description="æ£€æµ‹åˆ°å¼‚å¸¸çš„æ•æ„Ÿæ•°æ®è®¿é—®",
                   severity="high",
                   details=sensitive_access
               ))
           
           # 3. æ£€æµ‹è®¿é—®é¢‘ç‡çªå¢
           frequency_spike = self._detect_frequency_spike(access_logs)
           if frequency_spike:
               anomalies.append(Anomaly(
                   type="frequency_spike",
                   description="æ£€æµ‹åˆ°è®¿é—®é¢‘ç‡çªå¢",
                   severity="medium",
                   details=frequency_spike
               ))
           
           return anomalies
       
       def _detect_off_hours_access(self, access_logs: List[DataAccessLog]) -> List[DataAccessLog]:
           """æ£€æµ‹éå¸¸è§„æ—¶é—´è®¿é—®"""
           off_hours = []
           for log in access_logs:
               hour = log.timestamp.hour
               # æª¢æŸ¥æ˜¯å¦åœ¨æ­£å¸¸å·¥ä½œæ—¶é—´å¤– (å‡è®¾å·¥ä½œæ—¶é—´ä¸º9AM-6PM)
               if hour < 9 or hour > 18:
                   off_hours.append(log)
           return off_hours
       
       def _detect_sensitive_data_access(self, access_logs: List[DataAccessLog]) -> Optional[Dict]:
           """æ£€æµ‹æ•æ„Ÿæ•°æ®å¼‚å¸¸è®¿é—®"""
           sensitive_logs = [log for log in access_logs if log.sensitive_data_accessed]
           if not sensitive_logs:
               return None
           
           # æª¢æŸ¥æ•æ„Ÿæ•°æ®è®¿é—®æ¯”ä¾‹æ˜¯å¦å¼‚å¸¸é«˜
           total = len(access_logs)
           sensitive_count = len(sensitive_logs)
           ratio = sensitive_count / total
           
           if ratio > self.config.sensitive_data_threshold:
               return {
                   "sensitive_count": sensitive_count,
                   "total": total,
                   "ratio": ratio,
                   "threshold": self.config.sensitive_data_threshold
               }
           
           return None
       
       def _detect_frequency_spike(self, access_logs: List[DataAccessLog]) -> Optional[Dict]:
           """æ£€æµ‹è®¿é—®é¢‘ç‡çªå¢"""
           if len(access_logs) < 2:
               return None
           
           # è®¡ç®—æ—¶é—´é—´éš”
           time_diffs = [
               (access_logs[i].timestamp - access_logs[i-1].timestamp).total_seconds()
               for i in range(1, len(access_logs))
           ]
           
           # è®¡ç®—å¹³å‡é—´éš”å’Œæ ‡å‡†å·®
           avg_interval = sum(time_diffs) / len(time_diffs)
           std_dev = (sum((x - avg_interval) ** 2 for x in time_diffs) / len(time_diffs)) ** 0.5
           
           # æª¢æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çªå¢ï¼ˆé—´éš”è¿œå°äºå¹³å‡ï¼‰
           spike_threshold = max(1.0, avg_interval - 2 * std_dev)
           spikes = [diff for diff in time_diffs if diff < spike_threshold]
           
           if len(spikes) > self.config.spike_count_threshold:
               return {
                   "spike_count": len(spikes),
                   "threshold": spike_threshold,
                   "spike_count_threshold": self.config.spike_count_threshold
               }
           
           return None
       
       def _calculate_risk_score(
           self,
           pattern_analysis: Dict,
           anomaly_detection: List[Anomaly]
       ) -> float:
           """è®¡ç®—é£é™©è¯„åˆ†"""
           score = 0.0
           
           # åŸºäºå¼‚å¸¸
           for anomaly in anomaly_detection:
               weight = 0.3 if anomaly.severity == "high" else 0.1
               score += weight
           
           # åŸºäºæ•æ„Ÿæ•°æ®è®¿é—®æ¯”ä¾‹
           sensitive_ratio = pattern_analysis["by_data_source"].get("sensitive_data_ratio", 0)
           score += sensitive_ratio * 0.4
           
           # é™åˆ¶åœ¨0-1èŒƒå›´
           return min(1.0, max(0.0, score))
       
       def _row_to_log(self, row: Dict) -> DataAccessLog:
           """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸ºDataAccessLogå¯¹è±¡"""
           return DataAccessLog(
               id=row["id"],
               user_id=row["user_id"],
               project_id=row["project_id"],
               data_source_id=row["data_source_id"],
               access_type=row["access_type"],
               access_pattern=row["access_pattern"],
               data_categories=json.loads(row["data_categories"]),
               rows_accessed=row["rows_accessed"],
               columns_accessed=row["columns_accessed"],
               sensitive_data_accessed=row["sensitive_data_accessed"],
               ip_address=row["ip_address"],
               user_agent=row["user_agent"],
               timestamp=row["timestamp"]
           )

   # è¾…åŠ©ç±»å®šä¹‰
   class DataAccessLog:
       """æ•°æ®è®¿é—®æ—¥å¿—"""
       def __init__(
           self,
           id: str,
           user_id: str,
           project_id: str,
           data_source_id: Optional[str],
           access_type: str,
           access_pattern: str,
           data_categories: List[str],
           rows_accessed: int,
           columns_accessed: int,
           sensitive_data_accessed: bool,
           ip_address: str,
           user_agent: str,
           timestamp: datetime
       ):
           self.id = id
           self.user_id = user_id
           self.project_id = project_id
           self.data_source_id = data_source_id
           self.access_type = access_type
           self.access_pattern = access_pattern
           self.data_categories = data_categories
           self.rows_accessed = rows_accessed
           self.columns_accessed = columns_accessed
           self.sensitive_data_accessed = sensitive_data_accessed
           self.ip_address = ip_address
           self.user_agent = user_agent
           self.timestamp = timestamp

   class AccessPattern:
       """è®¿é—®æ¨¡å¼"""
       def __init__(
           self,
           pattern: List[str],
           frequency: int
       ):
           self.pattern = pattern
           self.frequency = frequency

   class Anomaly:
       """å¼‚å¸¸æ£€æµ‹ç»“æœ"""
       def __init__(
           self,
           type: str,
           description: str,
           severity: str,
           details: Dict
       ):
           self.type = type
           self.description = description
           self.severity = severity
           self.details = details

   class AccessPatternAnalysis:
       """è®¿é—®æ¨¡å¼åˆ†æç»“æœ"""
       def __init__(
           self,
           user_id: str,
           time_window: timedelta,
           total_accesses: int,
           pattern_analysis: Dict,
           anomaly_detection: List[Anomaly],
           risk_score: float,
           timestamp: datetime
       ):
           self.user_id = user_id
           self.time_window = time_window
           self.total_accesses = total_accesses
           self.pattern_analysis = pattern_analysis
           self.anomaly_detection = anomaly_detection
           self.risk_score = risk_score
           self.timestamp = timestamp
   ```

---

## ğŸ“‘ ç›¸å…³ç« èŠ‚

| å‰åº | å½“å‰ | åç»­ |
|-----|------|------|
| [7.7](ch7-7.md) | **7.8** | [7.9](ch7-9.md) |

**å¿«é€Ÿé“¾æ¥ï¼š**
- [â† è¿”å›ç¬¬7ç« é¦–é ](ch7-index.md)
