# 第10章：實時數據處理引擎 (Real-time Data Processing Engine)

## 10.1 模組概述

**[← 返回第10章首頁](ch10-index.md)**

---

## 🎯 模組定位

實時數據處理引擎是鏡界平台的核心擴展模組，專注於處理流式數據、實時計算和事件驅動場景。它填補了平台在實時處理能力上的空白，使平台能夠處理從秒級到毫秒級的實時數據流。

### 為什麼需要實時數據處理？

**當前痛點**:
- 批處理延遲高（分鐘到小時級別）
- 無法及時響應異常事件
- 實時監控能力不足
- 缺少流式數據分析

**解決方案**:
- 流式數據處理（秒級延遲）
- 實時事件觸發和告警
- 連續查詢和實時聚合
- 複雜事件處理（CEP）

---

## 🏗️ 核心架構

### 架構層次

```
┌─────────────────────────────────────────────────────┐
│                    應用層                             │
│  實時看板 │ 實時告警 │ 流量分析 │ 異常檢測           │
└─────────────────────────────────────────────────────┘
                        ↓↑
┌─────────────────────────────────────────────────────┐
│                   處理層                              │
│  ┌──────────────────────────────────────────────┐   │
│  │        Apache Flink 流處理引擎                │   │
│  │  - CEP  - Window  - State  - Watermark       │   │
│  └──────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────┘
                        ↓↑
┌─────────────────────────────────────────────────────┐
│                   存儲層                              │
│  Kafka │ RocksDB │ ClickHouse │ InfluxDB           │
└─────────────────────────────────────────────────────┘
                        ↓↑
┌─────────────────────────────────────────────────────┐
│                   數據源                              │
│  Ch8爬蟲 │ Ch3監測 │ Ch4工作流 │ 外部系統           │
└─────────────────────────────────────────────────────┘
```

---

## 💡 核心功能

### 1. 流式數據處理

#### 數據源接入
- **Kafka Source**: 從 Kafka topic 讀取數據
- **Socket Source**: TCP/UDP 數據流
- **File Source**: 監控文件變化
- **Custom Source**: 自定義數據源

#### 數據轉換
```python
# Flink 流處理示例
DataStream<Event> stream = env
    .addSource(new FlinkKafkaConsumer<>(topic, schema, properties))
    .filter(event -> event.isValid())  # 過濾
    .map(event -> transform(event))    # 轉換
    .keyBy(event -> event.getKey())    # 分組
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))  # 窗口
    .aggregate(new CountAggregator())  # 聚合
    .addSink(new FlinkKafkaProducer<>()); # 輸出
```

### 2. 時間窗口處理

#### 窗口類型

**滾動窗口（Tumbling Window）**
```
時間: 00:00  00:05  00:10  00:15  00:20
      [─────][─────][─────][─────]
       W1     W2     W3     W4
```
- 固定大小，無重疊
- 用於：每5分鐘統計

**滑動窗口（Sliding Window）**
```
時間: 00:00  00:02  00:04  00:06  00:08
      [────────]
         [────────]
            [────────]
               [────────]
```
- 固定大小，有重疊
- 用於：最近5分鐘移動平均

**會話窗口（Session Window）**
```
事件: E1  E2  E3      E4  E5         E6
      [─────────]     [─────]        [─]
       Session1      Session2     Session3
```
- 動態大小，基於活動間隔
- 用於：用戶會話分析

### 3. 複雜事件處理（CEP）

#### 模式匹配

**檢測異常登錄模式**
```java
Pattern<LoginEvent, ?> pattern = Pattern.<LoginEvent>begin("first")
    .where(new SimpleCondition<LoginEvent>() {
        @Override
        public boolean filter(LoginEvent event) {
            return event.isFailedLogin();
        }
    })
    .next("second")
    .where(new SimpleCondition<LoginEvent>() {
        @Override
        public boolean filter(LoginEvent event) {
            return event.isFailedLogin();
        }
    })
    .next("third")
    .where(new SimpleCondition<LoginEvent>() {
        @Override
        public boolean filter(LoginEvent event) {
            return event.isFailedLogin();
        }
    })
    .within(Time.minutes(5));  // 5分鐘內3次失敗登錄
```

### 4. 狀態管理

#### 狀態類型

**ValueState** - 單個值
```java
ValueState<Long> countState = getRuntimeContext()
    .getState(new ValueStateDescriptor<>("count", Long.class));
```

**ListState** - 列表
```java
ListState<Event> eventsState = getRuntimeContext()
    .getListState(new ListStateDescriptor<>("events", Event.class));
```

**MapState** - 鍵值對
```java
MapState<String, Long> mapState = getRuntimeContext()
    .getMapState(new MapStateDescriptor<>("map", String.class, Long.class));
```

---

## 🎯 應用場景

### 場景 1: 實時監控爬蟲狀態

```python
# 實時計算爬蟲 QPS
stream = env.add_source(KafkaSource("crawler-metrics"))
    .key_by(lambda x: x['crawler_id'])
    .window(TumblingProcessingTimeWindows.of(Time.seconds(10)))
    .aggregate(QPSAggregator())
    .filter(lambda x: x.qps < 10)  # QPS 異常低
    .add_sink(AlertSink())  # 發送告警
```

### 場景 2: 實時數據質量檢測

```python
# 檢測重複數據
stream = env.add_source(KafkaSource("raw-data"))
    .key_by(lambda x: x['url'])
    .process(DuplicateDetector())
    .filter(lambda x: x.is_duplicate)
    .add_sink(DuplicateStoreSink())
```

### 場景 3: 實時流量分析

```python
# 每分鐘訪問量 TOP 10 網站
stream = env.add_source(KafkaSource("access-logs"))
    .map(lambda x: (x['domain'], 1))
    .key_by(lambda x: x[0])
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .sum(1)
    .process(TopNProcessor(n=10))
    .add_sink(VisualizationSink())
```

---

## 📊 性能指標

### 處理能力

| 指標 | 目標值 | 說明 |
|------|--------|------|
| **吞吐量** | > 100萬 events/秒 | 單節點處理能力 |
| **延遲** | < 100ms（P99） | 端到端延遲 |
| **狀態大小** | 支持 TB 級 | 使用 RocksDB 存儲 |
| **容錯恢復** | < 1分鐘 | Checkpoint 恢復時間 |
| **水平擴展** | 線性擴展 | 增加節點提升處理能力 |

### 可靠性

- **Exactly-Once**: 保證精確一次語義
- **Checkpoint**: 分布式快照機制
- **Savepoint**: 手動保存點支持
- **自動恢復**: 失敗後自動重啟

---

## 🔗 與其他模組的集成

### 數據流向

```
┌─────────────┐
│  Ch8 爬蟲   │ ──Kafka──┐
└─────────────┘          │
                         ↓
┌─────────────┐     ┌──────────┐     ┌──────────────┐
│  Ch3 監測   │ ──→ │ Ch10 實時│ ──→ │ Ch3 監測告警 │
└─────────────┘     │   處理   │     └──────────────┘
                    └──────────┘
                         │
                         ├──→ ClickHouse (實時查詢)
                         ├──→ InfluxDB (時序數據)
                         └──→ Ch12 質量管理
```

### 接口規範

**輸入接口**
- Kafka Topic: `crawler.events`, `monitoring.metrics`
- REST API: `/api/v1/streams/publish`
- WebSocket: 實時數據推送

**輸出接口**
- Kafka Topic: `processed.events`, `alerts`
- ClickHouse: 實時OLAP查詢
- REST API: `/api/v1/streams/query`

---

## 🚀 快速開始

### 基礎示例

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.datastream.connectors import FlinkKafkaConsumer

# 1. 創建執行環境
env = StreamExecutionEnvironment.get_execution_environment()
env.set_parallelism(4)

# 2. 配置 Checkpoint
env.enable_checkpointing(60000)  # 每分鐘

# 3. 添加數據源
kafka_consumer = FlinkKafkaConsumer(
    topics='input-topic',
    deserialization_schema=JsonDeserializationSchema(),
    properties={'bootstrap.servers': 'localhost:9092'}
)
stream = env.add_source(kafka_consumer)

# 4. 數據處理
result = stream \
    .filter(lambda x: x['status'] == 'success') \
    .key_by(lambda x: x['source']) \
    .window(TumblingProcessingTimeWindows.of(Time.minutes(1))) \
    .aggregate(CountAggregator())

# 5. 輸出結果
result.add_sink(FlinkKafkaProducer(...))

# 6. 執行
env.execute("Real-time Processing Job")
```

---

## 📚 相關章節

- [10.2 詳細功能清單](ch10-2-詳細功能清單.md)
- [10.3 技術架構](ch10-3-技術架構.md)
- [10.4 核心組件詳細實現](ch10-4-核心組件詳細實現.md)
- [← 返回第10章首頁](ch10-index.md)

---

**最後更新**: 2025-10-31  
**版本**: 1.0


