# 鏡界平台 - 通用效能調優清單

本文檔提供系統化的效能調優檢查清單，適用於平台的所有模組。

---

## 📋 使用說明

### 檢查方式
- ✅ 已完成/已優化
- ⚠️ 需要注意/待改進  
- ❌ 存在問題/未實施

### 優先級
- 🔴 高優先級 - 立即處理
- 🟡 中優先級 - 計劃處理
- 🟢 低優先級 - 可選優化

---

## 1️⃣ 資料庫層面優化

### 索引優化
- [ ] 為常用查詢欄位創建索引
- [ ] 使用複合索引優化多條件查詢
- [ ] 定期分析和重建索引（REINDEX）
- [ ] 移除未使用的索引
- [ ] 使用部分索引減少索引大小

```sql
-- 檢查缺失的索引
SELECT schemaname, tablename, attname, n_distinct, correlation
FROM pg_stats
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY abs(correlation) DESC;

-- 檢查未使用的索引
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
WHERE idx_scan = 0;
```

### 查詢優化
- [ ] 使用 EXPLAIN ANALYZE 分析慢查詢
- [ ] 避免 SELECT *，只查詢需要的欄位
- [ ] 使用 JOIN 代替子查詢
- [ ] 批量操作代替循環單條
- [ ] 使用預編譯語句（Prepared Statements）

```python
# 優化前
for item in items:
    db.execute("INSERT INTO table VALUES (%s, %s)", (item.a, item.b))

# 優化後
data = [(item.a, item.b) for item in items]
db.executemany("INSERT INTO table VALUES (%s, %s)", data)
```

### 連接池配置
- [ ] 設置合適的最小/最大連接數
- [ ] 配置連接超時時間
- [ ] 啟用連接池監控
- [ ] 實現連接健康檢查
- [ ] 處理連接洩漏

```python
# 推薦配置
DATABASE_POOL = {
    'minconn': 5,
    'maxconn': 20,
    'timeout': 30,
    'max_overflow': 10,
    'pool_recycle': 3600  # 1小時回收
}
```

### 分區策略
- [ ] 對大表實施分區（按時間/ID）
- [ ] 定期歸檔歷史資料
- [ ] 使用分區裁剪優化查詢
- [ ] 自動化分區管理

---

## 2️⃣ 應用層面優化

### 緩存策略
- [ ] 實施多層緩存（記憶體 → Redis → DB）
- [ ] 設置合理的 TTL
- [ ] 使用緩存預熱
- [ ] 實現緩存失效策略
- [ ] 監控緩存命中率

```python
# 多層緩存示例
class MultiLevelCache:
    def get(self, key):
        # L1: 記憶體緩存
        if key in self.memory_cache:
            return self.memory_cache[key]
        
        # L2: Redis 緩存
        value = self.redis.get(key)
        if value:
            self.memory_cache[key] = value
            return value
        
        # L3: 資料庫
        value = self.db.query(key)
        if value:
            self.redis.setex(key, 300, value)
            self.memory_cache[key] = value
        
        return value
```

### 異步處理
- [ ] 使用訊息隊列處理耗時任務
- [ ] 實現非同步 API 端點
- [ ] 批量處理代替即時處理
- [ ] 使用背景任務處理非關鍵操作

```python
# 異步處理示例
from celery import Celery

@app.task
def process_heavy_task(data):
    # 耗時操作
    result = heavy_processing(data)
    return result

# API 端點
@app.post("/process")
async def process_endpoint(data: Dict):
    # 提交異步任務
    task = process_heavy_task.delay(data)
    return {"task_id": task.id, "status": "processing"}
```

### 資源池管理
- [ ] 實現線程池/進程池
- [ ] 設置合理的並發數
- [ ] 監控資源使用情況
- [ ] 實現資源回收機制

### API 優化
- [ ] 實施請求速率限制
- [ ] 使用分頁代替返回所有資料
- [ ] 實現欄位過濾（只返回需要的欄位）
- [ ] 壓縮 API 響應（gzip）
- [ ] 使用 ETags 實現條件請求

---

## 3️⃣ 系統層面優化

### CPU 優化
- [ ] 識別 CPU 密集型操作
- [ ] 使用多進程處理 CPU 密集任務
- [ ] 優化演算法複雜度
- [ ] 使用 JIT 編譯（PyPy）
- [ ] 考慮使用 Cython 優化關鍵路徑

```python
# CPU 分析
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# 執行代碼
your_function()

profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)
```

### 記憶體優化
- [ ] 識別記憶體洩漏
- [ ] 使用生成器代替列表
- [ ] 及時釋放大物件
- [ ] 使用記憶體映射處理大文件
- [ ] 監控記憶體使用趨勢

```python
# 使用生成器節省記憶體
def process_large_file(file_path):
    with open(file_path) as f:
        for line in f:  # 使用生成器，逐行讀取
            yield process_line(line)

# 記憶體分析
import tracemalloc

tracemalloc.start()
# 執行代碼
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

for stat in top_stats[:10]:
    print(stat)
```

### I/O 優化
- [ ] 使用異步 I/O（asyncio）
- [ ] 批量讀寫代替頻繁操作
- [ ] 使用緩衝區
- [ ] SSD 存儲關鍵資料
- [ ] 優化磁碟 I/O 模式

### 網路優化
- [ ] 啟用 HTTP/2 或 HTTP/3
- [ ] 使用 CDN 分發靜態資源
- [ ] 實施連接復用
- [ ] 優化 TCP 參數
- [ ] 壓縮網路傳輸資料

---

## 4️⃣ 架構層面優化

### 微服務拆分
- [ ] 識別效能瓶頸服務
- [ ] 獨立擴展高負載服務
- [ ] 實施服務降級
- [ ] 使用斷路器模式
- [ ] 實現服務限流

### 負載均衡
- [ ] 配置多個應用實例
- [ ] 使用負載均衡器（Nginx/HAProxy）
- [ ] 實施健康檢查
- [ ] 使用會話親和性（如需要）
- [ ] 監控負載分佈

### 水平擴展
- [ ] 設計無狀態服務
- [ ] 使用分布式緩存
- [ ] 實施資料庫讀寫分離
- [ ] 配置自動擴展（HPA）
- [ ] 資料分片策略

---

## 5️⃣ 監控與分析

### 效能指標
- [ ] 配置 APM（如 New Relic, DataDog）
- [ ] 監控關鍵指標（響應時間, 吞吐量）
- [ ] 設置效能告警閾值
- [ ] 定期生成效能報告
- [ ] 追蹤效能趨勢

```yaml
# Prometheus 關鍵指標
metrics:
  - http_request_duration_seconds  # 請求延遲
  - http_requests_total            # 請求總數
  - http_request_size_bytes        # 請求大小
  - http_response_size_bytes       # 響應大小
  - process_cpu_seconds_total      # CPU 使用
  - process_resident_memory_bytes  # 記憶體使用
```

### 日誌優化
- [ ] 使用結構化日誌
- [ ] 設置合適的日誌級別
- [ ] 實施日誌輪轉
- [ ] 集中化日誌管理
- [ ] 避免過度日誌記錄

### 追蹤分析
- [ ] 實施分布式追蹤（Jaeger/Zipkin）
- [ ] 追蹤關鍵業務流程
- [ ] 識別延遲瓶頸
- [ ] 分析調用鏈路

---

## 6️⃣ 代碼級優化

### 演算法優化
- [ ] 使用合適的資料結構
- [ ] 減少不必要的循環
- [ ] 避免重複計算
- [ ] 使用緩存避免重複查詢
- [ ] 提前終止條件

```python
# 優化前 - O(n²)
def find_duplicates(arr):
    duplicates = []
    for i in range(len(arr)):
        for j in range(i + 1, len(arr)):
            if arr[i] == arr[j]:
                duplicates.append(arr[i])
    return duplicates

# 優化後 - O(n)
def find_duplicates(arr):
    seen = set()
    duplicates = set()
    for item in arr:
        if item in seen:
            duplicates.add(item)
        seen.add(item)
    return list(duplicates)
```

### 並行處理
- [ ] 使用多線程處理 I/O 密集任務
- [ ] 使用多進程處理 CPU 密集任務
- [ ] 實施任務並行化
- [ ] 使用線程池/進程池

### 資源管理
- [ ] 使用上下文管理器（with）
- [ ] 及時關閉文件/連接
- [ ] 避免資源洩漏
- [ ] 實施資源限制

---

## 7️⃣ 第三方服務優化

### API 調用
- [ ] 實施請求重試機制
- [ ] 使用連接池
- [ ] 設置合理的超時
- [ ] 批量 API 調用
- [ ] 緩存 API 響應

### 外部依賴
- [ ] 評估第三方庫效能影響
- [ ] 使用輕量級替代方案
- [ ] 延遲載入非關鍵依賴
- [ ] 定期更新依賴版本

---

## 📊 效能基準

### 目標指標

| 指標 | 目標值 | 說明 |
|------|--------|------|
| API 響應時間（P95） | < 200ms | 95%的請求應在200ms內完成 |
| API 響應時間（P99） | < 500ms | 99%的請求應在500ms內完成 |
| 資料庫查詢（P95） | < 50ms | 95%的查詢應在50ms內完成 |
| 錯誤率 | < 0.1% | 錯誤率應低於0.1% |
| CPU 使用率 | < 70% | 平均CPU使用率應低於70% |
| 記憶體使用率 | < 80% | 平均記憶體使用率應低於80% |
| 緩存命中率 | > 90% | 緩存命中率應高於90% |

---

## 🔄 持續優化流程

1. **測量**: 收集當前效能數據
2. **分析**: 識別瓶頸和問題
3. **優化**: 實施改進措施
4. **驗證**: 測量優化效果
5. **重複**: 持續迭代改進

### 定期檢查
- [ ] 每週: 檢查關鍵指標
- [ ] 每月: 全面效能審查
- [ ] 每季: 架構優化評估
- [ ] 每年: 技術債務清理

---

## 📝 使用範例

### 模組應用

以 Ch1（資料源註冊中心）為例：

#### 已完成的優化 ✅
1. 資料庫層面
   - ✅ 為 name, url, category 創建索引
   - ✅ 實施連接池（minconn=10, maxconn=50）
   - ✅ 使用批量插入優化

2. 應用層面
   - ✅ Redis 緩存熱門資料源
   - ✅ Elasticsearch 全文搜索
   - ✅ API 速率限制（100 req/min）

#### 待優化項目 ⚠️
1. 系統層面
   - ⚠️ 記憶體使用監控
   - ⚠️ 慢查詢日誌分析

2. 架構層面
   - ⚠️ 讀寫分離
   - ⚠️ 水平擴展測試

---

**建議**: 根據實際業務需求和資源情況，優先處理高優先級項目，逐步完善系統效能。

**最後更新**: 2025-10-31

