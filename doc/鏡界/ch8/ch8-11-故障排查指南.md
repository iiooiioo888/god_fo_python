# 第8章：分布式爬蟲集群管理系統

## 8.11 故障排查指南

**[← 返回第8章首頁](ch8-index.md)**

---

## 🐛 常見問題

### 問題 1: 爬蟲節點頻繁離線

#### 症狀
- 節點狀態不穩定
- 任務執行失敗率高
- 節點心跳超時

#### 診斷步驟

```python
# 節點健康診斷工具
class NodeHealthDiagnostics:
    """節點健康診斷"""
    
    def diagnose_node(self, node_id: str) -> Dict:
        """診斷節點問題"""
        node = self.get_node(node_id)
        
        diagnostics = {
            'node_id': node_id,
            'issues': [],
            'metrics': {},
            'suggestions': []
        }
        
        # 檢查資源使用
        if node.cpu_usage > 90:
            diagnostics['issues'].append("CPU使用率過高")
            diagnostics['suggestions'].append("減少並發任務數或升級硬體")
        
        if node.memory_usage > 85:
            diagnostics['issues'].append("記憶體使用率過高")
            diagnostics['suggestions'].append("增加記憶體或優化爬蟲代碼")
        
        # 檢查網路連接
        if node.network_errors > 100:
            diagnostics['issues'].append("網路錯誤過多")
            diagnostics['suggestions'].append("檢查網路配置和代理設置")
        
        # 檢查心跳延遲
        if node.heartbeat_latency > 5000:  # 5秒
            diagnostics['issues'].append("心跳延遲過高")
            diagnostics['suggestions'].append("檢查網路連接和節點負載")
        
        return diagnostics
```

#### 解決方案

```python
class RobustNodeManager:
    """健壯的節點管理器"""
    
    def __init__(self):
        self.heartbeat_timeout = 30  # 30秒
        self.max_retries = 3
        self.backoff_multiplier = 2
    
    def handle_node_failure(self, node_id: str):
        """處理節點故障"""
        node = self.get_node(node_id)
        
        # 1. 重新分配任務
        tasks = self.get_node_tasks(node_id)
        self.redistribute_tasks(tasks)
        
        # 2. 嘗試重啟節點
        if self.can_restart(node):
            self.restart_node(node_id)
        
        # 3. 標記節點為不可用
        else:
            self.mark_node_unavailable(node_id)
            self.notify_admin(node_id, "Node failure")
    
    def redistribute_tasks(self, tasks: List[Task]):
        """重新分配任務"""
        available_nodes = self.get_available_nodes()
        
        for task in tasks:
            # 選擇負載最低的節點
            target_node = min(available_nodes, key=lambda n: n.current_load)
            self.assign_task(task, target_node)
```

---

### 問題 2: 爬取速度慢

#### 症狀
- 每秒請求數(RPS)低於預期
- 任務完成時間過長
- 系統資源使用率低

#### 解決方案

```python
class PerformanceOptimizer:
    """效能優化器"""
    
    def optimize_crawler_config(self, node: Node) -> Dict:
        """優化爬蟲配置"""
        config = node.config.copy()
        
        # 動態調整並發數
        if node.cpu_usage < 50 and node.memory_usage < 70:
            config['concurrent_requests'] = min(
                config['concurrent_requests'] * 1.5,
                100  # 最大值
            )
        elif node.cpu_usage > 80 or node.memory_usage > 85:
            config['concurrent_requests'] = max(
                config['concurrent_requests'] * 0.7,
                10  # 最小值
            )
        
        # 調整請求延遲
        if node.error_rate < 0.01:  # 錯誤率低於1%
            config['download_delay'] = max(config['download_delay'] * 0.8, 0.1)
        elif node.error_rate > 0.1:
            config['download_delay'] = min(config['download_delay'] * 1.5, 5)
        
        return config
```

---

### 問題 3: 反爬蟲封鎖

#### 症狀
- 大量 403/429 錯誤
- IP 被封鎖
- 驗證碼頻繁出現

#### 解決方案

```python
class AntiBlockingStrategy:
    """反封鎖策略"""
    
    def __init__(self):
        self.proxy_pool = ProxyPool()
        self.user_agent_rotator = UserAgentRotator()
    
    def get_request_config(self, url: str, retry_count: int = 0) -> Dict:
        """獲取請求配置（反封鎖）"""
        config = {
            'headers': self._get_headers(retry_count),
            'proxies': self._get_proxy(retry_count),
            'timeout': self._get_timeout(retry_count),
            'delay': self._get_delay(retry_count)
        }
        
        return config
    
    def _get_headers(self, retry_count: int) -> Dict:
        """獲取請求頭"""
        headers = {
            'User-Agent': self.user_agent_rotator.get_random(),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # 重試時添加更多偽裝
        if retry_count > 0:
            headers['Referer'] = 'https://www.google.com/'
            headers['DNT'] = '1'
        
        return headers
    
    def _get_proxy(self, retry_count: int) -> Dict:
        """獲取代理"""
        if retry_count == 0:
            return None  # 第一次嘗試不用代理
        
        # 從代理池獲取
        proxy = self.proxy_pool.get_random()
        return {
            'http': proxy,
            'https': proxy
        }
    
    def _get_delay(self, retry_count: int) -> float:
        """獲取延遲時間"""
        base_delay = 1
        return base_delay * (2 ** retry_count) + random.uniform(0, 1)
```

---

## 📊 效能監控

```python
class CrawlerMetricsCollector:
    """爬蟲指標收集器"""
    
    def collect_metrics(self) -> Dict:
        """收集指標"""
        return {
            'total_nodes': self.count_total_nodes(),
            'active_nodes': self.count_active_nodes(),
            'total_tasks': self.count_total_tasks(),
            'completed_tasks': self.count_completed_tasks(),
            'failed_tasks': self.count_failed_tasks(),
            'avg_task_duration': self.calculate_avg_duration(),
            'requests_per_second': self.calculate_rps(),
            'error_rate': self.calculate_error_rate(),
            'bandwidth_usage': self.get_bandwidth_usage()
        }
```

---

**相關章節**:
- [8.7 效能優化策略](ch8-7-效能優化策略.md)
- [← 返回第8章首頁](ch8-index.md)

