# ç¬¬2ç« ï¼šç¶²ç«™æŒ‡ç´‹åˆ†æå¼•æ“ (Website Fingerprint Engine)

## 2.11 æ•…éšœæ’æŸ¥æŒ‡å—

**[â† è¿”å›ç¬¬2ç« é¦–é ](ch2-index.md)**

---

æœ¬ç« ç¯€æä¾›ç¶²ç«™æŒ‡ç´‹åˆ†æå¼•æ“å¸¸è¦‹å•é¡Œçš„è¨ºæ–·å’Œè§£æ±ºæ–¹æ¡ˆã€‚

## ğŸ” å•é¡Œè¨ºæ–·æµç¨‹

```mermaid
graph TD
    A[ç™¼ç¾å•é¡Œ] --> B{å•é¡Œé¡å‹?}
    B -->|æŒ‡ç´‹åŒ¹é…å¤±æ•—| C[æª¢æŸ¥è¦å‰‡åº«]
    B -->|æ•ˆèƒ½å•é¡Œ| D[æª¢æŸ¥åˆ†æå™¨]
    B -->|çˆ¬å–å¤±æ•—| E[æª¢æŸ¥ç¶²è·¯]
    C --> F[æ›´æ–°è¦å‰‡]
    D --> G[å„ªåŒ–é…ç½®]
    E --> H[èª¿æ•´ç­–ç•¥]
    F --> I[æ¸¬è©¦é©—è­‰]
    G --> I
    H --> I
```

---

## ğŸ› å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### å•é¡Œ 1: æŒ‡ç´‹åŒ¹é…æº–ç¢ºç‡ä½

#### ç—‡ç‹€
- ç¶²ç«™è­˜åˆ¥éŒ¯èª¤ç‡è¶…é 10%
- ç›¸ä¼¼ç¶²ç«™ç„¡æ³•å€åˆ†
- æ–°ç¶²ç«™ç„¡æ³•è­˜åˆ¥

#### å¯èƒ½åŸå› 
1. æŒ‡ç´‹è¦å‰‡éæ™‚
2. ç‰¹å¾µæå–ä¸å®Œæ•´
3. åŒ¹é…é–¾å€¼è¨­ç½®ä¸ç•¶
4. ç¶²ç«™çµæ§‹è®ŠåŒ–

#### è¨ºæ–·æ­¥é©Ÿ

```python
# è¨ºæ–·å·¥å…·ï¼šæŒ‡ç´‹åŒ¹é…åˆ†æå™¨
class FingerprintDiagnostics:
    """æŒ‡ç´‹è¨ºæ–·å·¥å…·"""
    
    def __init__(self, fingerprint_service):
        self.service = fingerprint_service
        self.logger = logging.getLogger(__name__)
    
    def analyze_match_quality(self, url: str) -> Dict:
        """åˆ†æåŒ¹é…è³ªé‡"""
        result = self.service.analyze_website(url)
        
        analysis = {
            'url': url,
            'matched': result.matched,
            'confidence': result.confidence,
            'matched_features': result.matched_features,
            'missing_features': result.missing_features,
            'false_positives': result.false_positives
        }
        
        # è©³ç´°åˆ†æ
        if result.confidence < 0.7:
            analysis['issues'] = self._identify_issues(result)
            analysis['suggestions'] = self._generate_suggestions(result)
        
        return analysis
    
    def _identify_issues(self, result) -> List[str]:
        """è­˜åˆ¥å•é¡Œ"""
        issues = []
        
        if len(result.matched_features) < 3:
            issues.append("åŒ¹é…ç‰¹å¾µéå°‘")
        
        if len(result.missing_features) > 5:
            issues.append("ç¼ºå¤±é—œéµç‰¹å¾µ")
        
        if result.false_positives:
            issues.append(f"å­˜åœ¨èª¤å ±: {result.false_positives}")
        
        return issues
    
    def _generate_suggestions(self, result) -> List[str]:
        """ç”Ÿæˆå»ºè­°"""
        suggestions = []
        
        if len(result.matched_features) < 3:
            suggestions.append("éœ€è¦æ·»åŠ æ›´å¤šç‰¹å¾µè¦å‰‡")
        
        if result.missing_features:
            suggestions.append(f"å»ºè­°æ·»åŠ ç‰¹å¾µ: {', '.join(result.missing_features[:3])}")
        
        if result.confidence < 0.5:
            suggestions.append("å»ºè­°é‡æ–°è¨“ç·´åŒ¹é…æ¨¡å‹")
        
        return suggestions
    
    def batch_analyze(self, urls: List[str]) -> pd.DataFrame:
        """æ‰¹é‡åˆ†æ"""
        results = []
        
        for url in urls:
            try:
                analysis = self.analyze_match_quality(url)
                results.append(analysis)
            except Exception as e:
                self.logger.error(f"åˆ†æå¤±æ•— {url}: {e}")
        
        return pd.DataFrame(results)

# ä½¿ç”¨ç¯„ä¾‹
diagnostics = FingerprintDiagnostics(fingerprint_service)

# åˆ†æå–®å€‹ç¶²ç«™
analysis = diagnostics.analyze_match_quality("https://example.com")
print(f"ç½®ä¿¡åº¦: {analysis['confidence']}")
print(f"å•é¡Œ: {analysis.get('issues', [])}")
print(f"å»ºè­°: {analysis.get('suggestions', [])}")

# æ‰¹é‡åˆ†æ
urls = ["https://site1.com", "https://site2.com", ...]
results_df = diagnostics.batch_analyze(urls)
results_df.to_excel("fingerprint_analysis.xlsx")
```

#### è§£æ±ºæ–¹æ¡ˆ

**æ–¹æ¡ˆ 1: æ›´æ–°æŒ‡ç´‹è¦å‰‡åº«**

```python
class FingerprintRuleUpdater:
    """æŒ‡ç´‹è¦å‰‡æ›´æ–°å™¨"""
    
    def __init__(self, rule_repository):
        self.repo = rule_repository
    
    def extract_new_features(self, url: str, response: requests.Response) -> Dict:
        """å¾ç¶²ç«™æå–æ–°ç‰¹å¾µ"""
        soup = BeautifulSoup(response.content, 'html.parser')
        
        features = {
            'title_pattern': self._extract_title_pattern(soup),
            'meta_tags': self._extract_meta_tags(soup),
            'script_sources': self._extract_script_sources(soup),
            'css_selectors': self._extract_css_patterns(soup),
            'cookies': self._extract_cookie_patterns(response),
            'headers': self._extract_header_patterns(response),
            'dom_structure': self._extract_dom_structure(soup)
        }
        
        return features
    
    def _extract_title_pattern(self, soup) -> str:
        """æå–æ¨™é¡Œæ¨¡å¼"""
        title = soup.find('title')
        if title:
            # æå–æ¨™é¡Œçš„æ¨¡å¼ï¼ˆä¿ç•™é—œéµè©ï¼Œç§»é™¤è®Šé‡éƒ¨åˆ†ï¼‰
            text = title.string
            # ä½¿ç”¨æ­£å‰‡æå–æ¨¡å¼
            pattern = re.sub(r'\d+', '{num}', text)
            pattern = re.sub(r'[a-f0-9]{32}', '{hash}', pattern)
            return pattern
        return ""
    
    def _extract_script_sources(self, soup) -> List[str]:
        """æå–è…³æœ¬ä¾†æºç‰¹å¾µ"""
        scripts = soup.find_all('script', src=True)
        sources = []
        
        for script in scripts:
            src = script['src']
            # æ¨™æº–åŒ– URL
            if src.startswith('//'):
                src = 'https:' + src
            elif src.startswith('/'):
                continue  # è·³éç›¸å°è·¯å¾‘
            
            # æå–åŸŸåå’Œè·¯å¾‘æ¨¡å¼
            parsed = urlparse(src)
            pattern = f"{parsed.netloc}{parsed.path}"
            # ç§»é™¤ç‰ˆæœ¬è™Ÿ
            pattern = re.sub(r'[\d\.]+\.(js|css)$', 'X.\\1', pattern)
            sources.append(pattern)
        
        return sources
    
    def _extract_css_patterns(self, soup) -> List[str]:
        """æå– CSS æ¨¡å¼"""
        # æå–ç¨ç‰¹çš„ class åç¨±æ¨¡å¼
        elements = soup.find_all(class_=True)
        classes = []
        
        for element in elements[:100]:  # é™åˆ¶æ•¸é‡
            class_list = element.get('class', [])
            for cls in class_list:
                # åªä¿ç•™æœ‰æ„ç¾©çš„ classï¼ˆä¸æ˜¯å‹•æ…‹ç”Ÿæˆçš„ï¼‰
                if not re.match(r'^[a-z0-9]{20,}$', cls):
                    classes.append(cls)
        
        # è¿”å›æœ€å¸¸è¦‹çš„ class
        from collections import Counter
        return [cls for cls, _ in Counter(classes).most_common(10)]
    
    def create_rule(self, website_type: str, features: Dict) -> FingerprintRule:
        """å‰µå»ºæŒ‡ç´‹è¦å‰‡"""
        rule = FingerprintRule(
            id=generate_id(),
            website_type=website_type,
            features=features,
            weight={
                'title_pattern': 0.2,
                'meta_tags': 0.15,
                'script_sources': 0.25,
                'css_selectors': 0.15,
                'cookies': 0.1,
                'headers': 0.1,
                'dom_structure': 0.05
            },
            threshold=0.7,
            created_at=datetime.now()
        )
        
        return rule
    
    def update_rule_database(self, rules: List[FingerprintRule]):
        """æ›´æ–°è¦å‰‡åº«"""
        for rule in rules:
            existing = self.repo.get_by_website_type(rule.website_type)
            
            if existing:
                # åˆä½µç‰¹å¾µ
                merged_features = self._merge_features(
                    existing.features,
                    rule.features
                )
                existing.features = merged_features
                existing.updated_at = datetime.now()
                self.repo.update(existing)
            else:
                self.repo.create(rule)
        
        self.repo.commit()
    
    def _merge_features(self, old: Dict, new: Dict) -> Dict:
        """åˆä½µç‰¹å¾µ"""
        merged = old.copy()
        
        for key, value in new.items():
            if key in merged:
                if isinstance(value, list):
                    # åˆä½µåˆ—è¡¨ï¼Œå»é‡
                    merged[key] = list(set(merged[key] + value))
                elif isinstance(value, dict):
                    # åˆä½µå­—å…¸
                    merged[key].update(value)
            else:
                merged[key] = value
        
        return merged

# ä½¿ç”¨ç¯„ä¾‹
updater = FingerprintRuleUpdater(rule_repository)

# å¾ç¶²ç«™æå–ç‰¹å¾µ
response = requests.get("https://wordpress-site.com")
features = updater.extract_new_features("https://wordpress-site.com", response)

# å‰µå»ºè¦å‰‡
rule = updater.create_rule("WordPress", features)

# æ›´æ–°è¦å‰‡åº«
updater.update_rule_database([rule])
```

**æ–¹æ¡ˆ 2: æ”¹é€²ç‰¹å¾µæå–ç®—æ³•**

```python
class AdvancedFeatureExtractor:
    """é«˜ç´šç‰¹å¾µæå–å™¨"""
    
    def __init__(self):
        self.extractors = [
            self._extract_visual_features,
            self._extract_behavioral_features,
            self._extract_structural_features,
            self._extract_content_features
        ]
    
    def extract_all_features(self, url: str) -> Dict:
        """æå–æ‰€æœ‰ç‰¹å¾µ"""
        features = {}
        
        # ç²å–ç¶²é å…§å®¹
        response = self._fetch_with_js_rendering(url)
        
        # æ‡‰ç”¨æ‰€æœ‰æå–å™¨
        for extractor in self.extractors:
            try:
                extracted = extractor(url, response)
                features.update(extracted)
            except Exception as e:
                logging.error(f"ç‰¹å¾µæå–å¤±æ•— {extractor.__name__}: {e}")
        
        return features
    
    def _fetch_with_js_rendering(self, url: str) -> Dict:
        """ä½¿ç”¨ Selenium ç²å–æ¸²æŸ“å¾Œçš„å…§å®¹"""
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--disable-gpu')
        
        driver = webdriver.Chrome(options=options)
        driver.get(url)
        
        # ç­‰å¾…é é¢åŠ è¼‰
        time.sleep(3)
        
        result = {
            'html': driver.page_source,
            'cookies': driver.get_cookies(),
            'local_storage': driver.execute_script("return window.localStorage;"),
            'console_logs': driver.get_log('browser')
        }
        
        driver.quit()
        return result
    
    def _extract_visual_features(self, url: str, response: Dict) -> Dict:
        """æå–è¦–è¦ºç‰¹å¾µ"""
        from PIL import Image
        import io
        
        # æˆªåœ–
        driver = self._get_driver()
        driver.get(url)
        screenshot = driver.get_screenshot_as_png()
        
        # åˆ†ææˆªåœ–
        img = Image.open(io.BytesIO(screenshot))
        
        features = {
            'dominant_colors': self._get_dominant_colors(img),
            'layout_structure': self._analyze_layout(img),
            'logo_position': self._detect_logo_position(img)
        }
        
        return {'visual': features}
    
    def _extract_behavioral_features(self, url: str, response: Dict) -> Dict:
        """æå–è¡Œç‚ºç‰¹å¾µ"""
        features = {
            'ajax_calls': self._detect_ajax_calls(response),
            'websocket_usage': self._detect_websocket(response),
            'api_endpoints': self._extract_api_endpoints(response),
            'tracking_scripts': self._detect_tracking(response)
        }
        
        return {'behavioral': features}
    
    def _extract_structural_features(self, url: str, response: Dict) -> Dict:
        """æå–çµæ§‹ç‰¹å¾µ"""
        soup = BeautifulSoup(response['html'], 'html.parser')
        
        features = {
            'dom_depth': self._calculate_dom_depth(soup),
            'element_distribution': self._analyze_element_distribution(soup),
            'semantic_structure': self._analyze_semantic_html(soup)
        }
        
        return {'structural': features}
    
    def _extract_content_features(self, url: str, response: Dict) -> Dict:
        """æå–å…§å®¹ç‰¹å¾µ"""
        soup = BeautifulSoup(response['html'], 'html.parser')
        
        # æå–æ–‡æœ¬å…§å®¹
        text = soup.get_text()
        
        features = {
            'language': self._detect_language(text),
            'content_type': self._classify_content(text),
            'keywords': self._extract_keywords(text),
            'entities': self._extract_entities(text)
        }
        
        return {'content': features}
```

---

### å•é¡Œ 2: æŒ‡ç´‹åˆ†ææ•ˆèƒ½ç·©æ…¢

#### ç—‡ç‹€
- å–®å€‹ç¶²ç«™åˆ†æè¶…é 30 ç§’
- é«˜ä¸¦ç™¼æ™‚ç³»çµ±éŸ¿æ‡‰æ…¢
- CPU ä½¿ç”¨ç‡æŒçºŒé«˜æ–¼ 80%

#### è§£æ±ºæ–¹æ¡ˆ

**æ–¹æ¡ˆ 1: å¯¦ç¾åˆ†æçµæœç·©å­˜**

```python
from functools import lru_cache
import hashlib
from typing import Optional

class FingerprintCache:
    """æŒ‡ç´‹åˆ†æç·©å­˜"""
    
    def __init__(self, redis_client, ttl=3600):
        self.redis = redis_client
        self.ttl = ttl
    
    def _generate_key(self, url: str, options: Dict) -> str:
        """ç”Ÿæˆç·©å­˜éµ"""
        content = f"{url}:{json.dumps(options, sort_keys=True)}"
        return f"fingerprint:{hashlib.md5(content.encode()).hexdigest()}"
    
    def get(self, url: str, options: Dict) -> Optional[Dict]:
        """ç²å–ç·©å­˜"""
        key = self._generate_key(url, options)
        cached = self.redis.get(key)
        
        if cached:
            return json.loads(cached)
        return None
    
    def set(self, url: str, options: Dict, result: Dict):
        """è¨­ç½®ç·©å­˜"""
        key = self._generate_key(url, options)
        self.redis.setex(
            key,
            self.ttl,
            json.dumps(result)
        )
    
    def invalidate(self, url: str):
        """æ¸…é™¤ç·©å­˜"""
        pattern = f"fingerprint:*{hashlib.md5(url.encode()).hexdigest()}*"
        keys = self.redis.keys(pattern)
        if keys:
            self.redis.delete(*keys)

# ä½¿ç”¨ç·©å­˜çš„åˆ†ææœå‹™
class CachedFingerprintService:
    """å¸¶ç·©å­˜çš„æŒ‡ç´‹æœå‹™"""
    
    def __init__(self, fingerprint_service, cache):
        self.service = fingerprint_service
        self.cache = cache
    
    def analyze(self, url: str, options: Dict = None) -> Dict:
        """åˆ†æç¶²ç«™ï¼ˆå¸¶ç·©å­˜ï¼‰"""
        options = options or {}
        
        # å˜—è©¦å¾ç·©å­˜ç²å–
        cached_result = self.cache.get(url, options)
        if cached_result:
            cached_result['from_cache'] = True
            return cached_result
        
        # åŸ·è¡Œåˆ†æ
        result = self.service.analyze(url, options)
        
        # å­˜å…¥ç·©å­˜
        self.cache.set(url, options, result)
        result['from_cache'] = False
        
        return result
```

**æ–¹æ¡ˆ 2: ä¸¦è¡Œè™•ç†å„ªåŒ–**

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
from multiprocessing import Pool

class ParallelFingerprintAnalyzer:
    """ä¸¦è¡ŒæŒ‡ç´‹åˆ†æå™¨"""
    
    def __init__(self, max_workers=10):
        self.max_workers = max_workers
    
    def analyze_batch(self, urls: List[str]) -> List[Dict]:
        """æ‰¹é‡ä¸¦è¡Œåˆ†æ"""
        results = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            future_to_url = {
                executor.submit(self._analyze_single, url): url 
                for url in urls
            }
            
            # æ”¶é›†çµæœ
            for future in as_completed(future_to_url):
                url = future_to_url[future]
                try:
                    result = future.result(timeout=30)
                    results.append(result)
                except Exception as e:
                    logging.error(f"åˆ†æå¤±æ•— {url}: {e}")
                    results.append({
                        'url': url,
                        'error': str(e),
                        'success': False
                    })
        
        return results
    
    def _analyze_single(self, url: str) -> Dict:
        """åˆ†æå–®å€‹URL"""
        try:
            result = fingerprint_service.analyze(url)
            return {
                'url': url,
                'result': result,
                'success': True
            }
        except Exception as e:
            raise
```

---

## ğŸ“Š æ•ˆèƒ½ç›£æ§

```yaml
# Prometheus ç›£æ§é…ç½®
groups:
  - name: fingerprint_engine
    rules:
      - alert: SlowFingerprintAnalysis
        expr: histogram_quantile(0.95, rate(fingerprint_analysis_duration_seconds_bucket[5m])) > 10
        for: 5m
        annotations:
          summary: "æŒ‡ç´‹åˆ†æéæ…¢"
          description: "P95 å»¶é²è¶…é 10 ç§’"
      
      - alert: HighFingerprintErrorRate
        expr: rate(fingerprint_analysis_errors_total[5m]) / rate(fingerprint_analysis_total[5m]) > 0.1
        for: 5m
        annotations:
          summary: "æŒ‡ç´‹åˆ†æéŒ¯èª¤ç‡éé«˜"
          description: "éŒ¯èª¤ç‡è¶…é 10%"
```

---

**ç›¸é—œç« ç¯€**:
- [2.7 æ•ˆèƒ½å„ªåŒ–ç­–ç•¥](ch2-7-æ•ˆèƒ½å„ªåŒ–ç­–ç•¥.md)
- [2.10 æœ€ä½³å¯¦è¸æŒ‡å—](ch2-10-æœ€ä½³å¯¦è¸æŒ‡å—.md)
- [â† è¿”å›ç¬¬2ç« é¦–é ](ch2-index.md)

