# ç¬¬6ç« ï¼šAIè¼”åŠ©é–‹ç™¼ç³»çµ± (AI-Assisted Development System)

## 6.11 æ•…éšœæ’æŸ¥æŒ‡å—

**[â† è¿”å›ç¬¬6ç« é¦–é ](ch6-index.md)**

---

## ğŸ› å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

### å•é¡Œ 1: LLM API èª¿ç”¨å¤±æ•—

#### ç—‡ç‹€
- API è«‹æ±‚è¶…æ™‚
- é€Ÿç‡é™åˆ¶éŒ¯èª¤
- å›æ‡‰è³ªé‡å·®

#### è¨ºæ–·å·¥å…·

```python
class LLMDiagnostics:
    """LLM è¨ºæ–·å·¥å…·"""
    
    def diagnose_api_call(self, provider: str, model: str) -> Dict:
        """è¨ºæ–· API èª¿ç”¨"""
        diagnostics = {
            'provider': provider,
            'model': model,
            'issues': [],
            'metrics': {},
            'suggestions': []
        }
        
        # æ¸¬è©¦é€£æ¥
        connectivity = self._test_connectivity(provider)
        diagnostics['metrics']['connectivity'] = connectivity
        
        if not connectivity['success']:
            diagnostics['issues'].append("ç„¡æ³•é€£æ¥åˆ° API ç«¯é»")
            diagnostics['suggestions'].append("æª¢æŸ¥ç¶²è·¯é€£æ¥å’Œ API å¯†é‘°")
        
        # æ¸¬è©¦é€Ÿç‡é™åˆ¶
        rate_limit = self._test_rate_limit(provider, model)
        diagnostics['metrics']['rate_limit'] = rate_limit
        
        if rate_limit['remaining'] < rate_limit['limit'] * 0.1:
            diagnostics['issues'].append(f"é€Ÿç‡é™åˆ¶å³å°‡ç”¨ç›¡: {rate_limit['remaining']}/{rate_limit['limit']}")
            diagnostics['suggestions'].append("è€ƒæ…®å‡ç´šé…é¡æˆ–ä½¿ç”¨é€Ÿç‡é™åˆ¶å™¨")
        
        # æ¸¬è©¦éŸ¿æ‡‰æ™‚é–“
        latency = self._test_latency(provider, model)
        diagnostics['metrics']['latency'] = latency
        
        if latency > 10:  # ç§’
            diagnostics['issues'].append(f"éŸ¿æ‡‰æ™‚é–“éé•·: {latency}ç§’")
            diagnostics['suggestions'].append("è€ƒæ…®ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–å•Ÿç”¨æµå¼éŸ¿æ‡‰")
        
        return diagnostics
    
    def _test_connectivity(self, provider: str) -> Dict:
        """æ¸¬è©¦é€£æ¥"""
        try:
            response = requests.get(
                f"https://api.{provider}.com/health",
                timeout=5
            )
            return {
                'success': response.status_code == 200,
                'status_code': response.status_code
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
```

#### è§£æ±ºæ–¹æ¡ˆ

**æ–¹æ¡ˆ 1: å¯¦ç¾æ™ºèƒ½é‡è©¦æ©Ÿåˆ¶**

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

class RobustLLMClient:
    """å¥å£¯çš„ LLM å®¢æˆ¶ç«¯"""
    
    def __init__(self, api_key: str, base_url: str):
        self.api_key = api_key
        self.base_url = base_url
        self.session = self._create_session()
    
    def _create_session(self):
        """å‰µå»º HTTP Session"""
        session = requests.Session()
        session.headers.update({
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        })
        
        # é…ç½®é‡è©¦
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["POST"]
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        return session
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((requests.exceptions.Timeout, requests.exceptions.RequestException))
    )
    def chat_completion(
        self,
        messages: List[Dict],
        model: str = "gpt-3.5-turbo",
        temperature: float = 0.7,
        max_tokens: int = 1000,
        timeout: int = 30
    ) -> Dict:
        """èŠå¤©è£œå…¨ï¼ˆå¸¶é‡è©¦ï¼‰"""
        try:
            response = self.session.post(
                f"{self.base_url}/chat/completions",
                json={
                    "model": model,
                    "messages": messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens
                },
                timeout=timeout
            )
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:
                # é€Ÿç‡é™åˆ¶éŒ¯èª¤
                retry_after = int(e.response.headers.get('Retry-After', 60))
                self.logger.warning(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {retry_after} ç§’")
                time.sleep(retry_after)
                raise  # é‡è©¦
            else:
                raise
```

**æ–¹æ¡ˆ 2: å¯¦ç¾å›é€€ç­–ç•¥**

```python
class MultiProviderLLMClient:
    """å¤šæä¾›å•† LLM å®¢æˆ¶ç«¯"""
    
    def __init__(self):
        self.providers = [
            {'name': 'openai', 'client': OpenAIClient(), 'priority': 1},
            {'name': 'anthropic', 'client': AnthropicClient(), 'priority': 2},
            {'name': 'local', 'client': LocalLLMClient(), 'priority': 3}
        ]
        
        # æŒ‰å„ªå…ˆç´šæ’åº
        self.providers.sort(key=lambda x: x['priority'])
    
    def complete(self, prompt: str, **kwargs) -> str:
        """å®Œæˆè«‹æ±‚ï¼ˆè‡ªå‹•å›é€€ï¼‰"""
        last_error = None
        
        for provider in self.providers:
            try:
                self.logger.info(f"å˜—è©¦ä½¿ç”¨ {provider['name']}")
                
                result = provider['client'].complete(prompt, **kwargs)
                
                # é©—è­‰çµæœè³ªé‡
                if self._validate_response(result):
                    return result
                else:
                    self.logger.warning(f"{provider['name']} è¿”å›ä½è³ªé‡éŸ¿æ‡‰")
                    continue
                    
            except Exception as e:
                self.logger.error(f"{provider['name']} å¤±æ•—: {str(e)}")
                last_error = e
                continue
        
        # æ‰€æœ‰æä¾›å•†éƒ½å¤±æ•—
        raise Exception(f"æ‰€æœ‰ LLM æä¾›å•†éƒ½å¤±æ•—: {last_error}")
    
    def _validate_response(self, response: str) -> bool:
        """é©—è­‰éŸ¿æ‡‰è³ªé‡"""
        if not response or len(response) < 10:
            return False
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«éŒ¯èª¤è¨Šæ¯
        error_patterns = ['error', 'failed', 'unable to']
        if any(pattern in response.lower() for pattern in error_patterns):
            return False
        
        return True
```

---

### å•é¡Œ 2: ä»£ç¢¼ç”Ÿæˆè³ªé‡å·®

#### ç—‡ç‹€
- ç”Ÿæˆçš„ä»£ç¢¼ç„¡æ³•é‹è¡Œ
- é‚è¼¯éŒ¯èª¤
- ä¸ç¬¦åˆè¦ç¯„

#### è§£æ±ºæ–¹æ¡ˆ

```python
class CodeQualityValidator:
    """ä»£ç¢¼è³ªé‡é©—è­‰å™¨"""
    
    def __init__(self):
        self.validators = [
            self._validate_syntax,
            self._validate_imports,
            self._validate_style,
            self._validate_security
        ]
    
    def validate(self, code: str, language: str) -> Dict:
        """é©—è­‰ä»£ç¢¼è³ªé‡"""
        results = {
            'valid': True,
            'issues': [],
            'suggestions': [],
            'score': 100
        }
        
        for validator in self.validators:
            try:
                validator_result = validator(code, language)
                
                if not validator_result['valid']:
                    results['valid'] = False
                    results['issues'].extend(validator_result['issues'])
                    results['suggestions'].extend(validator_result['suggestions'])
                    results['score'] -= validator_result.get('penalty', 10)
                    
            except Exception as e:
                self.logger.error(f"é©—è­‰å™¨éŒ¯èª¤: {str(e)}")
        
        return results
    
    def _validate_syntax(self, code: str, language: str) -> Dict:
        """é©—è­‰èªæ³•"""
        if language == 'python':
            try:
                compile(code, '<string>', 'exec')
                return {'valid': True}
            except SyntaxError as e:
                return {
                    'valid': False,
                    'issues': [f"èªæ³•éŒ¯èª¤: {str(e)}"],
                    'suggestions': ["æª¢æŸ¥ä»£ç¢¼èªæ³•"],
                    'penalty': 30
                }
        
        return {'valid': True}
    
    def _validate_style(self, code: str, language: str) -> Dict:
        """é©—è­‰ä»£ç¢¼é¢¨æ ¼"""
        if language == 'python':
            import pycodestyle
            
            checker = pycodestyle.Checker('<string>', lines=code.splitlines())
            checker.check_all()
            
            if checker.results:
                return {
                    'valid': False,
                    'issues': [f"é¢¨æ ¼å•é¡Œ: {r}" for r in checker.results[:5]],
                    'suggestions': ["éµå¾ª PEP 8 è¦ç¯„"],
                    'penalty': 5
                }
        
        return {'valid': True}
    
    def _validate_security(self, code: str, language: str) -> Dict:
        """é©—è­‰å®‰å…¨æ€§"""
        # æª¢æŸ¥å±éšªå‡½æ•¸
        dangerous_patterns = [
            'eval(',
            'exec(',
            'os.system(',
            'subprocess.call(',
            '__import__'
        ]
        
        issues = []
        for pattern in dangerous_patterns:
            if pattern in code:
                issues.append(f"ç™¼ç¾æ½›åœ¨å±éšªå‡½æ•¸: {pattern}")
        
        if issues:
            return {
                'valid': False,
                'issues': issues,
                'suggestions': ["é¿å…ä½¿ç”¨å±éšªå‡½æ•¸", "ä½¿ç”¨æ›´å®‰å…¨çš„æ›¿ä»£æ–¹æ¡ˆ"],
                'penalty': 20
            }
        
        return {'valid': True}

class ImprovedCodeGenerator:
    """æ”¹é€²çš„ä»£ç¢¼ç”Ÿæˆå™¨"""
    
    def __init__(self, llm_client, validator):
        self.llm = llm_client
        self.validator = validator
        self.max_iterations = 3
    
    def generate(self, prompt: str, language: str = 'python') -> str:
        """ç”Ÿæˆé«˜è³ªé‡ä»£ç¢¼"""
        for iteration in range(self.max_iterations):
            # ç”Ÿæˆä»£ç¢¼
            code = self._generate_code(prompt, language, iteration)
            
            # é©—è­‰è³ªé‡
            validation = self.validator.validate(code, language)
            
            if validation['valid'] or validation['score'] >= 80:
                return code
            
            # æ ¹æ“šåé¥‹æ”¹é€²æç¤º
            prompt = self._improve_prompt(
                prompt,
                validation['issues'],
                validation['suggestions']
            )
        
        # è¿”å›æœ€ä½³å˜—è©¦
        return code
    
    def _improve_prompt(
        self,
        original_prompt: str,
        issues: List[str],
        suggestions: List[str]
    ) -> str:
        """æ”¹é€²æç¤º"""
        feedback = "\n".join([
            "ä¹‹å‰ç”Ÿæˆçš„ä»£ç¢¼å­˜åœ¨ä»¥ä¸‹å•é¡Œ:",
            *[f"- {issue}" for issue in issues],
            "\nè«‹æ ¹æ“šä»¥ä¸‹å»ºè­°æ”¹é€²:",
            *[f"- {suggestion}" for suggestion in suggestions]
        ])
        
        return f"{original_prompt}\n\n{feedback}"
```

---

## ğŸ“Š æ•ˆèƒ½ç›£æ§

```yaml
# Prometheus ç›£æ§
groups:
  - name: ai_assisted_dev
    rules:
      - alert: HighLLMErrorRate
        expr: rate(llm_api_errors_total[5m]) / rate(llm_api_requests_total[5m]) > 0.1
        annotations:
          summary: "LLM API éŒ¯èª¤ç‡éé«˜"
      
      - alert: SlowLLMResponse
        expr: histogram_quantile(0.95, rate(llm_response_duration_seconds_bucket[5m])) > 30
        annotations:
          summary: "LLM éŸ¿æ‡‰æ™‚é–“éé•·ï¼ˆP95 > 30ç§’ï¼‰"
      
      - alert: LowCodeQuality
        expr: avg(code_quality_score) < 70
        for: 10m
        annotations:
          summary: "ä»£ç¢¼ç”Ÿæˆè³ªé‡ä¸‹é™"
```

---

**ç›¸é—œç« ç¯€**:
- [6.7 æ•ˆèƒ½å„ªåŒ–ç­–ç•¥](ch6-7-æ•ˆèƒ½å„ªåŒ–ç­–ç•¥.md)
- [â† è¿”å›ç¬¬6ç« é¦–é ](ch6-index.md)

