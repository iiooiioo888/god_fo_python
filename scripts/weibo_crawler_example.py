#!/usr/bin/env python3
"""
å¾®åšUSIDçˆ¬èŸ²ä½¿ç”¨ç¤ºä¾‹

æ­¤è…³æœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¾®åšUSIDçˆ¬èŸ²ä¾†æ”¶é›†å¥³æ€§ç”¨æˆ¶ä¿¡æ¯
"""

import asyncio
import sys
import os
from pathlib import Path

# æ·»åŠ å¾Œç«¯è·¯å¾‘åˆ°Pythonè·¯å¾‘
backend_path = Path(__file__).parent.parent / "backend"
sys.path.insert(0, str(backend_path))

# åˆå§‹åŒ–æ¡†æ¶çµ„ä»¶
from utils.config_manager import init_config_manager
from utils.logger_service import init_logger_service

# åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
config_manager = init_config_manager(
    config_dir=str(backend_path / "config"),
    environment="development",
    enable_hot_reload=False
)

# åˆå§‹åŒ–æ—¥èªŒæœå‹™
logger_service = init_logger_service(config_manager)

from services.weibo_usid_crawler import (
    get_weibo_crawler,
    create_weibo_config,
    DataSource,
    WeibouserConfig
)


async def example_range_scan():
    """ç¯„åœæƒæç¤ºä¾‹"""
    print("ğŸ•·ï¸ å¾®åšUSIDçˆ¬èŸ² - ç¯„åœæƒæç¤ºä¾‹")
    print("=" * 50)

    # å‰µå»ºé…ç½®
    config = create_weibo_config(
        data_source=DataSource.RANGE_SCAN,
        uid_range_start=1669879400,  # ç¤ºä¾‹UIDç¯„åœ
        uid_range_end=1669879500,    # å°ç¯„åœæ¸¬è©¦
        max_concurrent=2,
        request_delay=1.5,
        csv_output_path="data/weibo_female_users_range.csv",
        cookie=""  # è«‹è¨­ç½®æ‚¨çš„å¾®åšcookie
    )

    print(f"æƒæç¯„åœ: {config.uid_range_start} - {config.uid_range_end}")
    print(f"ä¸¦ç™¼æ•¸: {config.max_concurrent}")
    print(f"è«‹æ±‚é–“éš”: {config.request_delay}ç§’")
    print()

    # é‹è¡Œçˆ¬èŸ²
    crawler = get_weibo_crawler()

    try:
        results = await crawler.crawl_female_users(config)

        print(f"âœ… çˆ¬å–å®Œæˆ!")
        print(f"æ‰¾åˆ°å¥³æ€§ç”¨æˆ¶: {len(results)}")

        if results:
            print("\nğŸ“Š å‰3å€‹çµæœ:")
            for i, user in enumerate(results[:3]):
                print(f"{i+1}. UID: {user.uid}, ç”¨æˆ¶å: {user.username}, "
                      f"æ€§åˆ¥: {user.gender.value}, ç›¸ç‰‡æ•¸: {user.photos_count}")

        print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {config.csv_output_path}")

    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±æ•—: {e}")

    finally:
        await crawler.close()


async def example_following_list():
    """é—œæ³¨åˆ—è¡¨ç¤ºä¾‹"""
    print("ğŸ•·ï¸ å¾®åšUSIDçˆ¬èŸ² - é—œæ³¨åˆ—è¡¨ç¤ºä¾‹")
    print("=" * 50)

    # æ³¨æ„: éœ€è¦æœ‰æ•ˆçš„å¾®åšç™»éŒ„cookie
    cookie = ""  # è«‹è¨­ç½®æ‚¨çš„å¾®åšcookie

    if not cookie:
        print("âŒ è«‹å…ˆè¨­ç½®å¾®åšç™»éŒ„cookie")
        print("ç²å–æ–¹æ³•:")
        print("1. ç™»éŒ„ https://weibo.cn")
        print("2. ä½¿ç”¨ç€è¦½å™¨é–‹ç™¼è€…å·¥å…·ç²å–cookie")
        print("3. åœ¨é…ç½®ä¸­è¨­ç½®cookieå­—æ®µ")
        return

    # å‰µå»ºé…ç½®
    config = create_weibo_config(
        data_source=DataSource.FOLLOWING_LIST,
        cookie=cookie,
        max_concurrent=3,
        request_delay=2.0,
        csv_output_path="data/weibo_female_users_following.csv"
    )

    print("æ•¸æ“šæº: é—œæ³¨åˆ—è¡¨")
    print(f"ä¸¦ç™¼æ•¸: {config.max_concurrent}")
    print(f"è«‹æ±‚é–“éš”: {config.request_delay}ç§’")
    print()

    # é‹è¡Œçˆ¬èŸ²
    crawler = get_weibo_crawler()

    try:
        results = await crawler.crawl_female_users(config)

        print(f"âœ… çˆ¬å–å®Œæˆ!")
        print(f"é—œæ³¨çš„å¥³æ€§ç”¨æˆ¶: {len(results)}")

        if results:
            print("\nğŸ“Š çµæœæ¨£æœ¬:")
            for i, user in enumerate(results[:5]):
                print(f"{i+1}. UID: {user.uid}, ç”¨æˆ¶å: {user.username}")

        print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {config.csv_output_path}")

    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±æ•—: {e}")

    finally:
        await crawler.close()


async def interactive_example():
    """äº¤äº’å¼ç¤ºä¾‹"""
    print("ğŸ•·ï¸ å¾®åšUSIDçˆ¬èŸ² - äº¤äº’å¼é…ç½®")
    print("=" * 50)

    # é¸æ“‡æ•¸æ“šæº
    print("é¸æ“‡æ•¸æ“šæº:")
    print("1. ç¯„åœæƒæ (æƒææŒ‡å®šUIDç¯„åœ)")
    print("2. é—œæ³¨åˆ—è¡¨ (ä½¿ç”¨ç•¶å‰ç”¨æˆ¶çš„é—œæ³¨åˆ—è¡¨)")
    choice = input("è«‹é¸æ“‡ (1æˆ–2): ").strip()

    data_source = None
    config_kwargs = {}

    if choice == "1":
        data_source = DataSource.RANGE_SCAN

        start = input("è¼¸å…¥èµ·å§‹UID (é»˜èª: 1000000000): ").strip()
        end = input("è¼¸å…¥çµæŸUID (é»˜èª: 1000010000): ").strip()

        config_kwargs.update({
            "uid_range_start": int(start) if start else 1000000000,
            "uid_range_end": int(end) if end else 1000010000
        })

    elif choice == "2":
        data_source = DataSource.FOLLOWING_LIST

        cookie = input("è¼¸å…¥å¾®åšcookie (å¿…å¡«): ").strip()
        if not cookie:
            print("âŒ Cookieç‚ºå¿…å¡«é …")
            return

        config_kwargs["cookie"] = cookie
    else:
        print("âŒ ç„¡æ•ˆé¸æ“‡")
        return

    # å…±ç”¨åƒæ•¸
    concurrent = input("æœ€å¤§ä¸¦ç™¼æ•¸ (é»˜èª: 3): ").strip()
    delay = input("è«‹æ±‚é–“éš”(ç§’) (é»˜èª: 2.0): ").strip()
    output = input("è¼¸å‡ºCSVè·¯å¾‘ (é»˜èª: data/weibo_female_users.csv): ").strip()

    config_kwargs.update({
        "max_concurrent": int(concurrent) if concurrent else 3,
        "request_delay": float(delay) if delay else 2.0,
        "csv_output_path": output if output else "data/weibo_female_users.csv"
    })

    # å‰µå»ºé…ç½®
    config = create_weibo_config(data_source, **config_kwargs)

    print("\nğŸ”§ é…ç½®ç¸½çµ:")
    print(f"æ•¸æ“šæº: {data_source.value}")
    if data_source == DataSource.RANGE_SCAN:
        print(f"UIDç¯„åœ: {config.uid_range_start} - {config.uid_range_end}")
    print(f"ä¸¦ç™¼æ•¸: {config.max_concurrent}")
    print(f"è«‹æ±‚é–“éš”: {config.request_delay}ç§’")
    print(f"è¼¸å‡ºè·¯å¾‘: {config.csv_output_path}")
    print()

    confirm = input("é–‹å§‹çˆ¬å–? (y/N): ").strip().lower()
    if confirm != 'y':
        print("å·²å–æ¶ˆ")
        return

    # é‹è¡Œçˆ¬èŸ²
    crawler = get_weibo_crawler()

    try:
        results = await crawler.crawl_female_users(config)

        print(f"\nâœ… çˆ¬å–å®Œæˆ!")
        print(f"æ‰¾åˆ°å¥³æ€§ç”¨æˆ¶: {len(results)}")

        if results:
            print("\nğŸ“Š çµæœæ¨£æœ¬:")
            for i, user in enumerate(results[:10]):
                print(f"{i+1}. {user.uid} - {user.username} - {user.gender.value}")

        print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {config.csv_output_path}")

    except Exception as e:
        print(f"\nâŒ çˆ¬å–å¤±æ•—: {e}")

    finally:
        await crawler.close()


def main():
    """ä¸»å‡½æ•¸"""
    print("å¾®åšUSIDçˆ¬èŸ²ç¤ºä¾‹")
    print("=" * 30)

    if len(sys.argv) > 1:
        mode = sys.argv[1]
        if mode == "range":
            asyncio.run(example_range_scan())
        elif mode == "following":
            asyncio.run(example_following_list())
        else:
            print(f"æœªçŸ¥æ¨¡å¼: {mode}")
            print("ä½¿ç”¨æ–¹æ³•: python weibo_crawler_example.py [range|following|interactive]")
    else:
        print("\né¸æ“‡é‹è¡Œæ¨¡å¼:")
        print("1. ç¯„åœæƒæç¤ºä¾‹ (python weibo_crawler_example.py range)")
        print("2. é—œæ³¨åˆ—è¡¨ç¤ºä¾‹ (python weibo_crawler_example.py following)")
        print("3. äº¤äº’å¼é…ç½® (é‹è¡Œæ­¤è…³æœ¬ä¸åŠ åƒæ•¸)")
        print()
        asyncio.run(interactive_example())


if __name__ == "__main__":
    # ç¢ºä¿æ•¸æ“šç›®éŒ„å­˜åœ¨
    Path("data").mkdir(exist_ok=True)

    main()
